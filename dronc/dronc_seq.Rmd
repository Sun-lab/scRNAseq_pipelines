---
title: "Workflow for single cell RNA-seq data analysis: DroNc-seq Dataset"
author: "Paul Little, Wei Sun"
date: "`r Sys.Date()`"
bibliography: [dronc_seq.bib]
biblio-style: apalike
output: 
  html_document:
    theme: journal
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: true
---

# Libraries

This workflow reanalyze the single nucleus RNA-seq data produced by [@habib2017massively], using DroNc-seq: massively parallel sNuc-seq with droplet technology. 

We will first load a few libraries. Among them, 
* ```DropletUtils``` provides functions for data from droplet technologies such as 10X Genomics. 
* ```biomaRt``` provides easy access to databases, such as Ensembl, COSMIC, Uniprot, HGNC, etc.
* ```scater``` is a collection of tools for doing quality control analyses of scRNA-seq
* ```scran``` provide functions for normalization of cell-specific libary sizes, correcting batch effects, and identification marker genes

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
num_cores = 7
```

We have requested `r num_cores` cores to improve SC3 runtime. 

```{r libraries, warning = FALSE, message = FALSE}

bio_packs = c("SingleCellExperiment","DropletUtils","biomaRt",
			"scater","scran","limma","org.Hs.eg.db","SC3")
source("https://bioconductor.org/biocLite.R")
for(pack1 in bio_packs){
	if( !pack1 %in% installed.packages()[,"Package"]){
		biocLite(pack1, suppressUpdates = TRUE)
	}
}

cran_packs = c("data.table","svd","Rtsne","stringi","irlba")
for(pack1 in cran_packs){
	if( !pack1 %in% installed.packages()[,"Package"]){
		install.packages(pack1)
	}
}

library(data.table)
library(SingleCellExperiment)
library(DropletUtils)
library(biomaRt)
library(scater)
library(scran)
library(limma)
library(ggplot2)

# src_dir   = "~/research/GitHub/scRNAseq_pipelines/dronc"
# work_dir  = "~/research/scRNAseq/workflow/data"
# dronc_dir = "~/research/scRNAseq/data/GTEx_droncseq_hip_pcf"
repo_dir = "/pine/scr/p/l/pllittle/CS_eQTL/s3_Real/scRNAseq_pipelines"
work_dir = file.path(repo_dir,"dronc")
dronc_dir = file.path(work_dir,"GTEx_droncseq_hip_pcf")

source(file.path(repo_dir,"SOURCE.R"))
```

# Obtaining/Loading Counts

Next we import in the count data and other available information. The dataset is available [here](https://storage.googleapis.com/gtex_additional_datasets/single_cell_data/GTEx_droncseq_hip_pcf.tar).

```{r import_counts}
counts_fn  = file.path(dronc_dir,"GTEx_droncseq_hip_pcf.umi_counts.txt.gz")
counts = fread(cmd = sprintf("zcat < %s",counts_fn),data.table = FALSE)
dim(counts); counts[1:3,1:2]

rownames(counts) = counts$V1
counts = as.matrix(counts[,-1])
colnames(counts)[1:10]
col_dat = smart_df(sample_name = colnames(counts),
	part_cell_id = sapply(colnames(counts),function(xx) 
		strsplit(xx,"_")[[1]][1],USE.NAMES=FALSE))
col_dat[1:5,]
```

Import clustering results. We utilize the supplemental files to label clusters and incorporate the existing TSNE results. Refer to the file nmeth.4407-S10.xlsx.

```{r import_col_data}
clust_fn = file.path(dronc_dir,"GTEx_droncseq_hip_pcf.clusters.txt.gz")
clust = fread(cmd = sprintf("zcat < %s",clust_fn),data.table = FALSE)
dim(clust); clust[1:5,]
names(clust) = c("sample_name","paper_clusters")
clust$paper_clusters = as.factor(clust$paper_clusters)

# Double check sample names
all(col_dat$sample_name == clust$sample_name)

map_clust_name = smart_df(paper_clusters = as.factor(seq(19)),
	paper_clusters_name = c("exPFC1","exPFC2","exCA1","exCA3",
		"GABA1","GABA2","exDG","ASC1","ASC2","ODC1","ODC2",
		"OPC","MG","NSC","END",rep(NA,4)),
	paper_cell_type = c("exPFC","exPFC","exCA1","exCA3",
		"GABA","GABA","exDG","ASC","ASC","ODC","ODC","OPC",
		"MG","NSC","END",rep(NA,4)))
clust = smart_merge(clust,map_clust_name)
clust = clust[match(col_dat$sample_name,clust$sample_name),]
clust[1:5,]

# Merge in TSNE results from paper
tsne_fn = file.path(dronc_dir,"GTEx_droncseq_hip_pcf.tsne.txt.gz")
df_tsne = fread(cmd = sprintf("zcat < %s",tsne_fn),data.table = FALSE)
dim(df_tsne); df_tsne[1:5,]
names(df_tsne) = c("sample_name",paste0("paper_TSNE",1:2))
table(df_tsne$sample_name == clust$sample_name)
table(df_tsne$sample_name == clust$sample_name)
is_match = (col_dat$sample_name == df_tsne$sample_name) & 
	(df_tsne$sample_name == clust$sample_name); table(is_match)

col_dat = cbind(col_dat,
				clust[,names(clust) != "sample_name"],
				df_tsne[,names(df_tsne) != "sample_name"])
col_dat[1:5,]

sce = SingleCellExperiment(assays = list(counts = counts),colData = col_dat)
sce

# Check for spike-ins
rownames(sce)[grep("^ERCC",rownames(sce))]

```

# Pre-processing and Quality Control

## Gene Annotation

We will extract annotation information based on gene names.

```{r warning = FALSE,message = FALSE}
anno_file = file.path(work_dir,"gene.annotation_dronc.rds")
if( file.exists(anno_file) ){

	gene_anno = readRDS(anno_file)

} else{

	ensembl = useEnsembl(biomart="ensembl",GRCh=37,
		dataset="hsapiens_gene_ensembl")

	attr_string = c("hgnc_symbol","external_gene_name","chromosome_name",
		"start_position","end_position","strand","description",
		"percentage_gene_gc_content","gene_biotype")

	gene_anno = getBM(attributes = attr_string,
		filters = "external_gene_name",
		values = rownames(sce),
		mart = ensembl)
	saveRDS(gene_anno, file=anno_file)
	
}

dim(sce); dim(gene_anno)

# Genes in annotation that aren't in sce
w2rm = which(!gene_anno$external_gene_name %in% rownames(sce))
w2rm
gene_anno[w2rm,]
gene_anno = gene_anno[-w2rm,]
dim(sce); dim(gene_anno)
```

Many genes have multiple entries in the annotation, often because they are annotated to scaffolds, assembly patches and alternate loci. Here we simply remove such entries. The we remove duplicated annotations and genes without annotations. 

```{r}
table(gene_anno$chromosome_name)[1:30]

chr_nms = c(1:22,"X","Y","MT")
gene_anno = gene_anno[which(gene_anno$chromosome_name %in% chr_nms),]
dim(sce); dim(gene_anno)

t1 = table(gene_anno$external_gene_name)
t2 = sort(t1[t1 > 1], decreasing=TRUE)
length(t2)
t2[1:10]

gene_anno[which(gene_anno$external_gene_name %in% names(t2)[1:4]), 1:4]
w_duplicate = which(gene_anno$external_gene_name %in% names(t2))
ganno2 = gene_anno[w_duplicate,]
dim(ganno2)

table(ganno2$hgnc_symbol == ganno2$external_gene_name)
ganno2 = ganno2[which(ganno2$hgnc_symbol == ganno2$external_gene_name),]
dim(ganno2)

ganno2 = dplyr::distinct(ganno2,external_gene_name,.keep_all = TRUE)
dim(ganno2)

gene_anno = rbind(gene_anno[-w_duplicate,], ganno2)
dim(gene_anno)
table(gene_anno$gene_biotype)

gene_missing = setdiff(rownames(sce),gene_anno$external_gene_name)
gene_missing[1:10]
length(gene_missing)

w2kp = match(gene_anno$external_gene_name,rownames(sce))
table(is.na(w2kp))
gene_anno$external_gene_name[which(is.na(w2kp))]
sce = sce[w2kp,]

dim(sce)
rowData(sce) = gene_anno

sce
rowData(sce)[1:5,]

```

## Identify Low quality cells

### barcodeRanks filtering
Please refer to [this workflow in bioconductor](https://bioconductor.org/packages/release/workflows/vignettes/simpleSingleCell/inst/doc/work-3-tenx.html#calling-cells-from-empty-droplets) for reference. 

```{r fig.dim = c(5,5)}
# Calling cells from empty droplets
bcrank = barcodeRanks(counts(sce))

# Only show unique points for plotting speed.
uniq = !duplicated(bcrank$rank)

par(mar=c(5,4,2,1), bty="n")
plot(bcrank$rank[uniq], bcrank$total[uniq], log="xy", 
	xlab="Rank", ylab="Total UMI count", cex=0.5, cex.lab=1.2)
abline(h=bcrank$inflection, col="darkgreen", lty=2,lwd=2)
abline(h=bcrank$knee, col="dodgerblue", lty=2,lwd=2)

legend("left", legend=c("Inflection", "Knee"), bty="n", 
	col=c("darkgreen", "dodgerblue"), lty=2, cex=1.2,lwd=2)

bcrank$inflection
bcrank$knee

summary(bcrank$total)
table(bcrank$total >= bcrank$knee)
table(bcrank$total >= bcrank$inflection)

set.seed(100)
date()
e_out = emptyDrops(counts(sce))
date()
e_out
length(unique(e_out$FDR))
table(e_out$FDR)

tapply(e_out$Total, e_out$FDR, summary)
```

From the above analysis, some cells with very small number of UMIs. Here we chose do not remove any cells because it appears all these 14,963 cells were used in the main anlaysis. Based on Figure 2 of their paper, there are 

> 14,963 DroNc-seq nuclei profiles (each with >10,000 reads and >200 genes)

### Incorporate information of mitochondira/ribosomal genes in QC metrics

We will generate a set of QC features per cell, including the expression of mitochondira/ribosomal genes.  We identify ribosomal genes based on annoation from https://www.genenames.org/.

```{r fig.dim = c(5,5), warning = FALSE, message = FALSE}
file_link = "https://www.genenames.org/cgi-bin/genefamilies/set/1054/download/branch"
ribo_fn = file.path(work_dir,"branch")
if( !file.exists(ribo_fn) ){
	cmd = sprintf("cd %s; wget %s",work_dir, file_link)
	print(cmd)
	system(cmd)
}

ribo = smart_RT(ribo_fn,sep='\t',header=TRUE,)
ribo[1:2,]

is_mito = which(rowData(sce)$chromosome_name == "MT")
is_ribo = which(rowData(sce)$external_gene_name %in% ribo$Approved.Symbol)
length(is_mito)
length(is_ribo)

sce = calculateQCMetrics(sce, feature_controls=list(Mt=is_mito, Ri=is_ribo))
sort(colnames(colData(sce)))

par(mfrow=c(2,2), mar=c(5, 4, 1, 1), bty="n")
hist(log10(sce$total_counts), xlab="log10(Library sizes)", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
hist(log10(sce$total_features), xlab="log10(# of expressed genes)", 
	main="", breaks=20, col="grey80", ylab="Number of cells")
hist(sce$pct_counts_Ri, xlab="Ribosome prop. (%)",
    ylab="Number of cells", breaks=40, main="", col="grey80")
hist(sce$pct_counts_Mt, xlab="Mitochondrial prop. (%)", 
    ylab="Number of cells", breaks=80, main="", col="grey80")

par(mfrow=c(2,2), mar=c(5, 4, 1, 1), bty="n")
smoothScatter(log10(sce$total_counts), log10(sce$total_features), 
	xlab="log10(Library sizes)", ylab="log10(# of expressed genes)")
smoothScatter(log10(sce$total_counts), sce$pct_counts_Ri,
	xlab="log10(Library sizes)", ylab="Ribosome prop. (%)")
smoothScatter(log10(sce$total_counts), sce$pct_counts_Mt,
	xlab="log10(Library sizes)", ylab="Mitochondrial prop. (%)")
smoothScatter(sce$pct_counts_Ri,sce$pct_counts_Mt,
	xlab="Ribosome prop. (%)", ylab="Mitochondrial prop. (%)")
```

From the QC results, we will filter on the metrics by identifying outliers using `isOutlier`.
```{r}
libsize_drop = isOutlier(sce$total_counts,nmads = 3,type = "lower",log = TRUE)
feature_drop = isOutlier(sce$total_features_by_counts,nmads = 3,type = "lower",log = TRUE)
mito_drop = isOutlier(sce$pct_counts_Mt,nmads = 3,type = "higher")
ribo_drop = isOutlier(sce$pct_counts_Ri,nmads = 3,type = "higher")
keep = !(libsize_drop | feature_drop | mito_drop | ribo_drop)
smart_df(ByLibSize = sum(libsize_drop),ByFeature = sum(feature_drop),
		ByMito = sum(mito_drop),ByRibo = sum(ribo_drop),
		Remaining = sum(keep))

smart_table(colData(sce)$paper_clusters,keep)
smart_table(colData(sce)$paper_clusters_name,keep)
# Notice that paper_cluster = 18 samples will all be excluded

sce = sce[,keep]
dim(sce)
```

## Summarize gene level information
```{r warning = FALSE, message = FALSE, fig.dim = c(8,3)}
rowData(sce)[1:2,]
summary(rowData(sce)$mean_counts)
summary(rowData(sce)$mean_counts[rowData(sce)$mean_counts>0])
summary(rowData(sce)$n_cells_counts)

par(mfrow=c(1,3), mar=c(5,4,1,1))
hist(log10(rowData(sce)$mean_counts+1e-6), col="grey80",  main="", 
	breaks=40, xlab="log10(ave # of UMI + 1e-6)")
hist(log10(rowData(sce)$n_cells_counts+1), col="grey80", main="", 
	breaks=40, xlab="log10(# of expressed cells + 1)")
plot(log10(rowData(sce)$mean_counts+1e-6), pch=16, col=rgb(0,0,0,0.4), 
	log10(rowData(sce)$n_cells_counts + 1), 
	xlab="log10(ave # of UMI + 1e-6)", 
	ylab="log10(# of expressed cells + 1)")

tb1 = table(rowData(sce)$n_cells_counts)
tb1[1:11]
```

We remove those genes that are lowly expressed. [@habib2017massively] mentioned in section "Gene detection and quality controls" of *Online Methods*

> Nuclei with less than 200 detected genes and less than 10,000 usable reads were filtered out.

and 

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it. For each analysis, genes were removed that were detected in less than 10 nuclei.

Therefore it seems we should remove all the cells having less than 200 genes with two or more UMI counts. However, this would remove majorify of the cells. Therefore, we conlcude that they meant to remove the cells having less than 200 genes with one or more UMI counts. To filter genes, we follow their threshold to remove genes with two or more UMIs in less than 10 nuclei.

Note that the variable _strand_ need to be renamed, otherwise there is an error message that such a variabel name cannot be used. 

```{r}
names(rowData(sce))[names(rowData(sce)) == "strand"] = "strand_n"

n_genes = colSums(counts(sce) >= 2)
summary(n_genes)
table(n_genes >= 100)
table(n_genes >= 200)

n_genes = colSums(counts(sce) >= 1)
summary(n_genes)
table(n_genes >= 100)
table(n_genes >= 200)

n_cells = rowSums(counts(sce) >= 2)
summary(n_cells)
table(n_cells >= 10)

sce = sce[which(n_cells >= 10),]
dim(sce)
```

Next we check those highly expressed genes 
```{r fig.dim = c(5,5)}
par(mar=c(5,4,1,1))
od1 = order(rowData(sce)$mean_counts, decreasing = TRUE)
barplot(rowData(sce)$mean_counts[od1[20:1]], las=1, 
		names.arg=rowData(sce)$hgnc_symbol[od1[20:1]], 
		horiz=TRUE, cex.names=0.8, cex.axis=0.8, 
		xlab="ave # of UMI")
```

## Normalization
A simple solution for normalization and stablizing expression varaince across genes is to tranform the count data by log(count/size.factor + 1). One may calcualte size.factor per cell as the total number of UMIs, and this assumes the total expression are the same across all the cells. However, the total expression of each cell may vary with respect to cell type and/or cell size, and the ```computeSumFactors``` function in R package scran provides a more sophisicated way to calcualte size.factor to allow such variaation across cells [@lun2016pooling]. ```computeSumFactors``` can use initial clustering of cells to normalize expression within and beetween clusters.  Within a cluster, it estimates the size factor for many groups of cells so that there are more groups than cells, and then it can calcualte the size factor per cell using a lienar deconvolution system. 

As shown in the following plot, the final size factor estimation is indeed highly correlated with the naive definition by total count. 

Finally, the command ```normalize(sce)``` adds the normalized expression into the variable ```sce```, which can be accessed by ````logcounts(sce) = log2(gene_cell_count / size_factor + 1)````.

```{r normalize,warning = FALSE,message = FALSE,fig.dim = c(5,5)}

date()
clusters = quickCluster(sce, min.mean=0.1, method="igraph")
table(clusters)
date()
sce = computeSumFactors(sce, cluster=clusters, min.mean=0.1)
date()
summary(sizeFactors(sce))
sort(sizeFactors(sce))[1:30]

# Remove cells with negative or very small size factors
dim(sce)
sce = sce[,which(sizeFactors(sce) > 0.01)]
dim(sce)

par(mfrow=c(1,2), mar=c(5,4,2,1), bty="n")
smoothScatter(sce$total_counts, sizeFactors(sce), log="xy", 
				xlab="total counts", ylab="size factors")
plot(sce$total_counts, sizeFactors(sce), log="xy", 
	xlab="total counts", ylab="size factors", 
	cex=0.3, pch=20, col=rgb(0.1,0.2,0.7,0.3))
abline(h=0.05)

dim(sce)
sce = sce[,which(sizeFactors(sce) > 0.05)]
dim(sce)

sce = normalize(sce) 
```

## Dimension Reduction
For dimension reduction, such as calculating PCA or performing TSNE, we should start by identifying a subset of genes with high level of biological signal relative to background (technical) noise. The ```decomposeVar``` function from R/cran is designed for this task. 

```{r warning = FALSE,message = FALSE,fig.dim = c(5,5)}

new_trend = makeTechTrend(x=sce)
fit = trendVar(sce, use.spikes=FALSE, loess.args=list(span=0.05))

par(mfrow=c(1,1), mar=c(5,4,2,1), bty="n")
plot(fit$mean, fit$var, pch=20, col=rgb(0.1,0.2,0.7,0.6), 
	xlab="log(mean)", ylab="var")
curve(fit$trend(x), col="orange", lwd=2, add=TRUE)
curve(new_trend(x), col="red", lwd=2, add=TRUE)
legend("top", legend=c("Poisson noise", "observed trend"), 
		lty=1, lwd=2, col=c("red", "orange"), bty="n")

fit$trend = new_trend
# obtain bio, FDR, pvalues for testing for HVGs (highly variable genes)
dec = decomposeVar(fit=fit) 
top_dec = dec[order(dec$bio, decreasing=TRUE),]
plotExpression(sce, features=rownames(top_dec)[1:10])
```

When performing PCA, we can use all the genes or just those genes with high signal-to-noise ratio. TSNE analysis is usually based on the top PCs rather than the original gene expression data. We first perform PCA using all the genes and the function ```denoisePCA``` can automatically select the PCs based on modeling of technical noise.

```{r denoisepca, fig.dim = c(7,7)}
date()
sce = denoisePCA(sce,technical=new_trend,approx=TRUE) # Using the Poisson trend fit
# sce = denoisePCA(sce,technical=fit$trend,approx=TRUE) # Using the observed trend fit
date()
dim(reducedDim(sce,"PCA"))

par(mfrow=c(1,1))
plot(log10(attr(reducedDim(sce), "percentVar")), xlab="PC",
	ylab="log10(Prop of variance explained)", pch=20, cex=0.6, 
	col=rgb(0.8, 0.2, 0.2, 0.5))
abline(v=ncol(reducedDim(sce,"PCA")), lty=2, col="red")

df_redDim = smart_df(colData(sce)[,c("sample_name","part_cell_id",
	paste0("paper_TSNE",1:2),"log10_total_features","paper_clusters",
	"paper_clusters_name","paper_cell_type")],
	reducedDim(sce, "PCA")[,1:2])
rownames(df_redDim) = NULL

# all_vars = c("part_cell_id","log10_total_features","paper_clusters",
# 	"paper_clusters_name","paper_cell_type")

ggplot_custom(DATA = df_redDim,X = "paper_TSNE1",Y = "paper_TSNE2",COL = "part_cell_id",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "paper_TSNE1",Y = "paper_TSNE2",COL = "log10_total_features",TYPE = "cont")
ggplot_custom(DATA = df_redDim,X = "paper_TSNE1",Y = "paper_TSNE2",COL = "paper_clusters",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "paper_TSNE1",Y = "paper_TSNE2",COL = "paper_clusters_name",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "paper_TSNE1",Y = "paper_TSNE2",COL = "paper_cell_type",TYPE = "cat")

# ggplot_custom(DATA = df_redDim,X = "PC1",Y = "PC2",COL = "part_cell_id",TYPE = "cat")
# ggplot_custom(DATA = df_redDim,X = "PC1",Y = "PC2",COL = "log10_total_features",TYPE = "cont")
# ggplot_custom(DATA = df_redDim,X = "PC1",Y = "PC2",COL = "paper_clusters",TYPE = "cat")
# ggplot_custom(DATA = df_redDim,X = "PC1",Y = "PC2",COL = "paper_clusters_name",TYPE = "cat")
# ggplot_custom(DATA = df_redDim,X = "PC1",Y = "PC2",COL = "paper_cell_type",TYPE = "cat")

date()
sce = runTSNE(sce,use_dimred="PCA",perplexity=30,rand_seed=100)
date()

tmp_df = smart_df(reducedDim(sce,"TSNE"))
rownames(tmp_df) = NULL
names(tmp_df) = paste0("my_TSNE",1:2)
df_redDim = smart_df(df_redDim,tmp_df); rm(tmp_df)
df_redDim[1:5,]

ggplot_custom(DATA = df_redDim,X = "my_TSNE1",Y = "my_TSNE2",COL = "part_cell_id",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "my_TSNE1",Y = "my_TSNE2",COL = "log10_total_features",TYPE = "cont")
ggplot_custom(DATA = df_redDim,X = "my_TSNE1",Y = "my_TSNE2",COL = "paper_clusters",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "my_TSNE1",Y = "my_TSNE2",COL = "paper_clusters_name",TYPE = "cat")
ggplot_custom(DATA = df_redDim,X = "my_TSNE1",Y = "my_TSNE2",COL = "paper_cell_type",TYPE = "cat")

saveRDS(list(sce = sce,dec = dec,df_redDim = df_redDim),
		file.path(work_dir,"post_redDim_all_genes.rds"))
# Note that this contains the results from PCA and TSNE with all genes
# rds = readRDS("post_redDim_all_genes.rds"); sce = rds$sce; dec = rds$dec; df_redDim = rds$df_redDim; rm(rds)
```

We select around top 1000 genes for the PCA and use the top 50 PCs for TSNE projection. 

```{r select_hvg, warning = FALSE,message = FALSE,fig.dim = c(5,5)}

library(svd)
library(Rtsne)

summary(dec$bio)
dec1 = dec
dec1$bio[which(dec$bio < 1e-5)] = 1e-5
dec1$FDR[which(dec$FDR < 1e-100)] = 1e-100

par(mfrow=c(1,2))
hist(log10(dec1$bio),breaks=100,main="")
hist(log10(dec1$FDR),breaks=100,main="")

summary(dec$FDR[dec$bio > 0.01])
summary(dec$FDR[dec$bio > 0.03])
table(dec$FDR < 1e-10,dec$bio > 0.03)
table(dec$FDR < 1e-10,dec$bio > 0.01)
table(dec$FDR < 1e-10,dec$bio > 0.02)

# Subsetting genes based on FDR and biological residual thresholds
w2kp = which(dec$FDR < 1e-10 & dec$bio > 0.02)
sce_hvg = sce[w2kp,]
sce_hvg

# Extracting log2(norm_express+1)
edat = t(as.matrix(logcounts(sce_hvg)))
edat = scale(edat)
dim(edat)
edat[1:2,1:3]

# Perform SVD on sce_hvg
date()
ppk = propack.svd(edat,neig=50)
date()
pca = t(ppk$d*t(ppk$u)) # calculates pc scores aka principal components

tmp_df = smart_df(pca[,1:2])
names(tmp_df) = paste0("HVG_PC",seq(ncol(tmp_df)))

df_hvg = smart_df(colData(sce)[,c("sample_name","part_cell_id",
	paste0("paper_TSNE",1:2),"log10_total_features","paper_clusters",
	"paper_clusters_name","paper_cell_type")],tmp_df)
rownames(df_hvg) = NULL

# ggplot_custom(DATA = df_hvg,X = "HVG_PC1",Y = "HVG_PC2",COL = "part_cell_id",TYPE = "cat")
# ggplot_custom(DATA = df_hvg,X = "HVG_PC1",Y = "HVG_PC2",COL = "log10_total_features",TYPE = "cont")
# ggplot_custom(DATA = df_hvg,X = "HVG_PC1",Y = "HVG_PC2",COL = "paper_clusters",TYPE = "cat")
# ggplot_custom(DATA = df_hvg,X = "HVG_PC1",Y = "HVG_PC2",COL = "paper_clusters_name",TYPE = "cat")
# ggplot_custom(DATA = df_hvg,X = "HVG_PC1",Y = "HVG_PC2",COL = "paper_cell_type",TYPE = "cat")

set.seed(100)
date()
tsne = Rtsne(pca, pca = FALSE)
date()

tmp_df = smart_df(tsne$Y)
names(tmp_df) = paste0("HVG_TSNE",seq(ncol(tmp_df)))
df_hvg = smart_df(df_hvg,tmp_df)

ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = "part_cell_id",TYPE = "cat")
ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = "log10_total_features",TYPE = "cont")
ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = "paper_clusters",TYPE = "cat")
ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = "paper_clusters_name",TYPE = "cat")
ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = "paper_cell_type",TYPE = "cat")

reducedDims(sce_hvg) = SimpleList(PCA=pca, TSNE=tsne$Y)
sce_hvg
saveRDS(sce_hvg,file.path(work_dir,"post_HVG.rds"))
```

## Clustering

### Kmeans
Next we cluster the cells using a simple kmeans method on the top 50 PCs. We set the number of clusters to be 5 thru 15, to include the 12 cell types reported by [@habib2017massively]. 
```{r kmeans, warning = FALSE,message = FALSE,fig.dim = c(6,6)}

all_num_clust = c(5:15)
df_hvg = df_hvg[,!grepl("^KM_",names(df_hvg))]

for(num_clust in all_num_clust){
	cat(paste0("KM with ",num_clust," clusters.\n"))
	kmeans_out = kmeans(reducedDim(sce_hvg, "PCA"), 
					centers = num_clust, 
					iter.max = 1e8,nstart = 2500,
					algorithm = "MacQueen")
	km_label = paste0("KM_",num_clust)
	df_hvg[[km_label]] = as.factor(kmeans_out$cluster)

	print(smart_table(df_hvg$paper_cell_type,kmeans_out$cluster))
	print(smart_table(df_hvg$paper_clusters_name,kmeans_out$cluster))
	print(ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2", 
						COL = km_label,TYPE = "cat"))

}

saveRDS(list(sce_hvg=sce_hvg,df_hvg=df_hvg,all_num_clust=all_num_clust),
		file.path(work_dir,"post_kmeans.rds"))
```

### SC3
Next seek to cluster cells using another method SC3. The code used here is based on [SC3 manual](https://bioconductor.org/packages/devel/bioc/vignettes/SC3/inst/doc/SC3.html#run-sc3). By default, when there are more than 5000 genes, SC3 will 

> selects a subset of cells uniformly at random (5,000), and obtains clusters from this subset. The inferred labels can be used to train a Support Vector Machine (SVM), which is employed to assign labels to the remaining cells.

By default, SC3 filter genes to select those with dropout percentage between 10 and 90%. 

```{r}
summary(rowData(sce)$pct_dropout_counts)
table(rowData(sce)$pct_dropout_counts < 90)
```

This will end up with 1418 genes. However, we found the clustering resutls using these 1418 genes have considerable discrepency with clustering resutls from Kmeans and cell types reported by [@habib2017massively]. Therefore, we chose to use those genes identified from previous step for SC3.

```{r sc3, cache=TRUE, warning = FALSE, message = FALSE, fig.dim=c(8,8)}
library(SC3)
rowData(sce_hvg)$feature_symbol = rowData(sce_hvg)$external_gene_name
date()
all_ks = c(10,12)
sce_hvg = sc3(sce_hvg,gene_filter = FALSE,
			n_cores = num_cores,ks = all_ks,biology = TRUE, 
			rand_seed = 100,svm_num_cells = 2000)
date()

dim(colData(sce_hvg))
colData(sce_hvg)[1:2,1:5]
names(colData(sce_hvg))

# Run SVM and predict labels of all other cells
date()
sce_hvg = sc3_run_svm(sce_hvg, ks = all_ks)
date()

```

Next we compare the clustering results from SC3 and the reported cell types.
```{r post_sc3, fig.dim = c(8,8),fig.path='figures/', dev=c('png')}

for(one_ks in all_ks){
	sc3_label = paste0("sc3_",one_ks,"_clusters")
	df_hvg[[sc3_label]] = as.factor(colData(sce_hvg)[,sc3_label])

	print(smart_table(df_hvg$paper_cell_type, df_hvg[[sc3_label]]))

	print(ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",Y = "HVG_TSNE2", 
						COL = sc3_label,TYPE = "cat"))
}

saveRDS(list(sce_hvg=sce_hvg,df_hvg=df_hvg,all_ks=all_ks),
		file.path(work_dir,"post_sc3.rds"))
```


## Compare our kmeans to SC3 and to DrocNc clustering

We obtainted the cell type and clustering resutls from [@habib2017massively]. Supplementary Table 10: supplement nmeth.4407-S10.xlsx file. Here we compare the cell type reported by Habib et al. (2017) with ours. Habib et al. (2017) identified genes with high variation by fitting a gamma distribution on the relation between mean and coefficient of variation and chose the number of PCs based on "the largest eigen value gap". It was not clear what is the number of PCs used. Then they used these top PCs to perform tSNE anlaysis and clustering using a graph based method. 

```{r fig.dim = c(7,7)}
tmp_lab = smart_RT(file.path(work_dir,"cluster_num_label.txt"), 
					sep = "\t",header = TRUE)
tmp_lab
tmp_lab = name_change(tmp_lab,"Name","Cluster.Name")
tmp_lab = name_change(tmp_lab,"Name.1","Cell_Type")

tmp_res = smart_RT(file.path(work_dir,"paper_cluster_res.txt"), 
					sep = "\t",header = TRUE,comment.char = "")
dim(tmp_res); tmp_res[1:5,]
tmp_res = name_change(tmp_res,"X.Genes","nGenes")
tmp_res = name_change(tmp_res,"X.Transcripts","nTranscripts")

tmp_res = smart_merge(tmp_res, tmp_lab[,c("Cluster.Name","Cell_Type")], 
					all.x=TRUE)

summary(tmp_res$nGenes)
smart_hist(tmp_res$nGenes,breaks=50,main="",xlab="number of genes per cell")
df_hvg$Cell.ID = colnames(sce_hvg)

smart_table(df_hvg$Cell.ID %in% tmp_res$Cell.ID)
tmp_res$Cell.ID[!(tmp_res$Cell.ID %in% df_hvg$Cell.ID)][1:5]
tmp_res$Cell.ID = gsub("-",".",tmp_res$Cell.ID)
table(df_hvg$Cell.ID %in% tmp_res$Cell.ID)

# Merge and compare
all_clust_res = smart_merge(df_hvg,tmp_res)
sc3_res = smart_df(colData(sce_hvg)[,paste0("sc3_",all_ks,"_clusters")])
for(ks in all_ks){
	sc3_label = paste0("sc3_",ks,"_clusters")
	sc3_res[,sc3_label] = as.factor(sc3_res[,sc3_label])
}
sc3_res$Cell.ID = colnames(sce_hvg)
all_clust_res = smart_merge(all_clust_res, sc3_res)
dim(all_clust_res)
all_clust_res[1:5,]

smart_table(all_clust_res[,c("Cell_Type","Cluster.ID")])
for(num_clust in all_num_clust){
	km_label = paste0("KM_",num_clust)
	print(smart_table(all_clust_res[,c("Cell_Type",km_label)]))
	t2 = melt(smart_table(all_clust_res[,c("Cell_Type",km_label)]))
	colnames(t2)[2] = "cluster"
	print(summary(t2$value))
	print(gg.heatmap(t2,paste0("kmeans ",num_clust," clusters")))
}

for(ks in all_ks){
	sc3_label = paste0("sc3_",ks,"_clusters")
	print(smart_table(all_clust_res[,c("Cell_Type",sc3_label)]))
	t2 = melt(smart_table(all_clust_res[,c("Cell_Type",sc3_label)]))
	colnames(t2)[2] = "cluster"
	print(summary(t2$value))
	print(gg.heatmap(t2,paste0("sc3 ",ks," clusters")))
}

```

We plot our TSNE colored by our clustering results. 
```{r fig.dim = c(7,7)}
all_vars = c("Cell_Type",paste0("KM_",all_num_clust),
			paste0("sc3_",all_ks,"_clusters"))
for(one_var in all_vars){
	print(ggplot_custom(DATA = all_clust_res,X = "HVG_TSNE1",
		Y = "HVG_TSNE2",COL = one_var,TYPE = "cat"))
}
```

Next we plot the TSNE by Habib et al. (2017). and colored by our clustering results. 

```{r fig.dim = c(7,7)}
all_vars = c("Cell_Type",paste0("KM_",all_num_clust),
			paste0("sc3_",all_ks,"_clusters"))
for(one_var in all_vars){
	print(ggplot_custom(DATA = all_clust_res,X = "paper_TSNE1",
		Y = "paper_TSNE2",COL = one_var,TYPE = "cat"))
}
```

Finally we save the sce object and the clustering results

```{r}
saveRDS(sce,file.path(work_dir,"sce.rds"))
saveRDS(sce_hvg,file.path(work_dir,"sce_hvg.rds"))
saveRDS(all_clust_res,file.path(work_dir,"all_clust_res.rds"))

```


# Session information
```{r}
sessionInfo()
```

# Reference
