---
title: "A workflow for single cell RNA-seq data analysis: MTG dataset"
author: "Paul Little, Wei Sun"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: journal
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: true
bibliography: MTG.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This markdown is for analyzing the [Allen Brain Atlas MTG dataset](http://celltypes.brain-map.org/rnaseq). While some details of their analysis is provided [here](http://help.brain-map.org/download/attachments/8323525/CellTypes_Transcriptomics_Overview.pdf), we ran a workflow similar to the DroNc dataset.

The packages required for the analysis are as follows:
- DropletUtils: provides functions for data from droplet technologies such as 10X Genomics
- biomaRt: provides easy access to databases, such as Ensembl, COSMIC, Uniprot, HGNC, etc.
- scater: collection of tools for doing quality control analyses of scRNA-seq
- scran: methods provide normalization of cell-specific biases, correcting batch effects, identify marker genes
- SC3: package for single cell consensus clustering.

# Obtaining/Loading Counts

The dataset is available [here](http://celltypes.brain-map.org/api/v2/well_known_file_download/694416044). This markdown is designed to download all necessary packages and input data objects for analysis.

Before running this R markdown, change the following `repo_dir` and `data_dir` variables to your own respective local working directory. Also, determine if the analysis will be conducted with exon counts only(`exon_only = TRUE`) or with both exon and intron counts summed together (`exon_only = FALSE`). I have requested 5 cores to improve SC3 runtime.

```{r}
# Specifying working directories
repo_dir = "/pine/scr/p/l/pllittle/CS_eQTL/s3_Real/scRNAseq_pipelines"
data_dir = file.path(repo_dir,"MTG")
setwd(data_dir)

# Analysis Plans
exon_only = TRUE
num_cores = 1

# Source/Libraries
source(file.path(repo_dir,"SOURCE.R"))
# biocLite("BiocUpgrade")
bio_packs = c("SingleCellExperiment","DropletUtils","biomaRt","scater","scran","SC3")
if( !all(bio_packs %in% installed.packages()[,"Package"]) ){
        source("https://bioconductor.org/biocLite.R")
        biocLite(bio_packs,suppressUpdates = TRUE)
}
cran_packs = c("stringi","irlba")
if( !all(cran_packs %in% installed.packages()[,"Package"]) ){
        install.packages(cran_packs)
}
suppressPackageStartupMessages(library(SingleCellExperiment))
suppressPackageStartupMessages(library(DropletUtils))
suppressPackageStartupMessages(library(biomaRt))
suppressPackageStartupMessages(library(scater))
suppressPackageStartupMessages(library(scran))
suppressPackageStartupMessages(library(limma))

# Import counts
if( exon_only ){
	counts_fn = file.path(data_dir,"exons.rds")
} else {
	counts_fn = file.path(data_dir,"exons_introns.rds")
}
if( !file.exists(counts_fn) ){
	file_link = "http://celltypes.brain-map.org/api/v2/well_known_file_download/694416044"
	file_name = strsplit(file_link,"/")[[1]]
	file_name = file_name[length(file_name)]
	file_name = file.path(data_dir,file_name)
	if( !file.exists(file_name) ){
		cmd = sprintf("cd %s; wget %s",data_dir,file_link)
		system(cmd)
	}
	cmd = sprintf("cd %s; unzip -o %s",data_dir,file_name); system(cmd)
	
	exons_fn = file.path(data_dir,"human_MTG_2018-06-14_exon-matrix.csv")
	num_lines = as.numeric(system(sprintf("wc -l %s | cut -d ' ' -f1",exons_fn),intern = TRUE))
	cat(paste0("Reading in ",exons_fn,"\n"))
	exon_counts = read.delim(exons_fn,sep = ',',header = TRUE,row.names = 1,check.names = FALSE,nrows = num_lines - 1)
	exon_counts = as.matrix(exon_counts)

	introns_fn = file.path(data_dir,"human_MTG_2018-06-14_intron-matrix.csv")
	num_lines = as.numeric(system(sprintf("wc -l %s | cut -d ' ' -f1",introns_fn),intern = TRUE))
	cat(paste0("Reading in ",introns_fn,"\n"))
	intron_counts = read.delim(introns_fn,sep = ',',header = TRUE,row.names = 1,check.names = FALSE,nrows = num_lines - 1)
	intron_counts = as.matrix(intron_counts)

	exon_intron_counts = exon_counts + intron_counts
	
	saveRDS(exon_counts,file.path(data_dir,"exons.rds"))
	saveRDS(intron_counts,file.path(data_dir,"introns.rds"))
	saveRDS(exon_intron_counts,file.path(data_dir,"exons_introns.rds"))
}

counts = readRDS(counts_fn)
cell_data = smart_RT("human_MTG_2018-06-14_samples-columns.csv",sep=',',header=TRUE)

# Double check samples are correctly sorted
all(colnames(counts) == cell_data$sample_name)
sce = SingleCellExperiment(assays = list(counts = as.matrix(counts)),colData = cell_data)
colData(sce)$cluster0 = sapply(colData(sce)$cluster,function(xx) strsplit(xx," ")[[1]][1],USE.NAMES=FALSE)
colData(sce)$cluster0[which(colData(sce)$cluster0 == "no")] = "no class"
rm(counts,cell_data)

# Import gene info
gene_dat = smart_RT("human_MTG_2018-06-14_genes-rows.csv",sep=',',header=TRUE)
all(rownames(sce) == as.character(gene_dat$entrez_id))
rowData(sce) = gene_dat; rm(gene_dat)
rownames(sce) = rowData(sce)$gene
sce

# Checking spikes
rowData(sce)[grep("^ERCC",rowData(sce)$gene),]
sce

```

# Pre-processing: Quality Control, Gene Detection, Normalization

### Incorporate Mito and Ribo to calculate QC metrics

Next step we apply QC based on a set of features per cell. We will look at ribosomal genes. The imported file can be found [here](https://www.genenames.org/cgi-bin/genefamilies/set/1054/download/branch).

```{r}
file_link = "https://www.genenames.org/cgi-bin/genefamilies/set/1054/download/branch"
file_name = strsplit(file_link,"/")[[1]]
file_name = file_name[length(file_name)]
ribo_fn = file.path(data_dir,file_name)
if( !file.exists(ribo_fn) ){
	cmd = sprintf("cd %s; wget %s",data_dir,file_link)
	print(cmd)
	system(cmd)
}

ribo = smart_RT(ribo_fn,sep='\t',header=TRUE)
dim(ribo)
ribo[1:2,]

table(rowData(sce)$chromosome)
is_mito = which(rowData(sce)$chromosome == "MT")
is_ribo = which(rowData(sce)$gene %in% ribo$Approved.Symbol)
length(is_mito)
length(is_ribo)
```

Now we will calculate QC metrics for each sample. The code and filtering below are motivated by the vignette presented [here](https://bioconductor.org/packages/release/workflows/vignettes/simpleSingleCell/inst/doc/work-1-reads.html#32_identifying_outliers_for_each_metric).
```{r fig.width = 12,fig.height = 12}
sort(names(colData(sce)))
sort(names(rowData(sce)))
sce = calculateQCMetrics(sce,feature_controls=list(Mt=is_mito, Ri=is_ribo))
sort(names(colData(sce)))
sort(names(rowData(sce)))

par(mfrow=c(2,2), mar=c(5, 4, 1, 1), bty="n")
smart_hist(log10(sce$total_counts),xlab="log10(Library sizes)", main="", 
	breaks=20,ylab="Number of cells")
smart_hist(log10(sce$total_features),xlab="log10(# of expressed genes)", 
	main="", breaks=20,ylab="Number of cells")
smart_hist(sce$pct_counts_Ri, xlab="Ribosome prop. (%)",
	ylab="Number of cells", breaks=40, main="")
smart_hist(sce$pct_counts_Mt, xlab="Mitochondrial prop. (%)", 
	ylab="Number of cells", breaks=80, main="")
smoothScatter(log10(sce$total_counts), log10(sce$total_features), 
	xlab="log10(Library sizes)", ylab="log10(# of expressed genes)", 
	nrpoints=500, cex=0.5)
smoothScatter(log10(sce$total_counts), sce$pct_counts_Ri, 
	xlab="log10(Library sizes)", ylab="Ribosome prop. (%)",
	nrpoints=500, cex=0.5)
smoothScatter(log10(sce$total_counts), sce$pct_counts_Mt, 
	xlab="log10(Library sizes)", ylab="Mitochondrial prop. (%)",
	nrpoints=500, cex=0.5)
smoothScatter(sce$pct_counts_Ri, sce$pct_counts_Mt, 
	xlab="Ribosome prop. (%)", ylab="Mitochondrial prop. (%)",
	nrpoints=500, cex=0.5)
smart_hist(sce$pct_counts_Ri,breaks=40,xlab="Ribosome prop. (%)")
smart_hist(sce$pct_counts_Mt,breaks=40,xlab="Mitochondrial prop. (%)")
plot(x=sce$pct_counts_Ri,y=sce$pct_counts_Mt,pch=16,col=rgb(0,0,0,0.4),
	xlab="Ribosome prop. (%)", ylab="Mitochondrial prop. (%)")
# ribo_cut = 1.5; mito_cut = 1; abline(v=ribo_cut,lty=2); abline(h=mito_cut,lty=2)
par(mfrow=c(1,1))

# Removing outliers defined as being lower or higher than 3 MADs from the median of each metric
libsize_drop = isOutlier(sce$total_counts,nmads=3,type="lower",log=TRUE)
feature_drop = isOutlier(sce$total_features_by_counts,nmads=3,type="lower",log=TRUE)
mito_drop = isOutlier(sce$pct_counts_Mt,nmads=3,type="higher")
ribo_drop = isOutlier(sce$pct_counts_Ri,nmads=3,type="higher")

keep = !(libsize_drop | feature_drop | mito_drop | ribo_drop)
data.frame(ByLibSize=sum(libsize_drop),ByFeature=sum(feature_drop),
    ByMito=sum(mito_drop),ByRibo=sum(ribo_drop),Remaining=sum(keep))
```

We then subset the `sce` object to keep high quality samples(cells). In addition, we save the original object. 
```{r}
sce$PassQC = keep
saveRDS(sce,"preQC.rds")
sce = sce[,keep]
dim(sce)

# To load image
# sce = readRDS("preQC.rds"); sce = sce[,which(colData(sce)$PassQC == TRUE)]
```

## Summarize gene-level information
```{r fig.width=12,fig.height=12}

rowData(sce)[1:2,]
summary(rowData(sce)$mean_counts)
summary(rowData(sce)$mean_counts[rowData(sce)$mean_counts>0])
summary(rowData(sce)$n_cells_counts)

par(mfrow=c(2,2), mar=c(5,4,1,1))
smart_hist(log10(rowData(sce)$mean_counts+1e-6),main="",
	breaks=40, xlab="log10(ave # of UMI + 1e-6)")
smart_hist(log10(rowData(sce)$n_cells_counts+1),main="",
	breaks=40, xlab="log10(# of expressed cells + 1)")
smoothScatter(log10(rowData(sce)$mean_counts+1e-6),
	log10(rowData(sce)$n_cells_counts + 1),
	xlab="log10(ave # of UMI + 1e-6)",
	ylab="log10(# of expressed cells + 1)")
par(mfrow=c(1,1),mar=c(5,4,4,2)+0.1)

tb1 = table(rowData(sce)$n_cells_counts)
tb1[1:11]

# Filter genes
par(mfrow=c(2,1),mar=c(5,4,1,1))
smart_hist(rowData(sce)$n_cells_counts,breaks=50,xlab="# of expressed cells")
smart_hist(log10(1+rowData(sce)$n_cells_counts),breaks=50,xlab="log10(1 + # of expressed cells)")
par(mfrow=c(1,1))

n_cell_count_filter = rowData(sce)$n_cells_counts > 5
	table(n_cell_count_filter)
min_detect_min_sample = apply(counts(sce),1,function(xx) length(which(xx > 0)) > 10)
	table(min_detect_min_sample)
min_mean_counts0 = rowData(sce)$mean_counts > 0
	table(min_mean_counts0)
min_mean_counts1 = rowData(sce)$mean_counts > 1
	table(min_mean_counts1)
table(n_cell_count_filter,min_detect_min_sample,min_mean_counts0,min_mean_counts1)

sce = sce[which(rowData(sce)$mean_counts > 1),]
dim(sce)

# Next we check those highly expressed genes 
par(mfrow=c(1,2),mar=c(5,8,1,1))
od1 = order(rowData(sce)$mean_counts, decreasing = TRUE)
barplot(rowData(sce)$mean_counts[od1[20:1]], las=1, 
	names.arg=rowData(sce)$gene[od1[20:1]], 
	horiz=TRUE, cex.names=1, cex.axis=0.7, 
	xlab="ave # of UMI")
barplot(log10(rowData(sce)$mean_counts[od1[20:1]]), las=1, 
	names.arg=rowData(sce)$gene[od1[20:1]], 
	horiz=TRUE, cex.names=1, cex.axis=0.7, 
	xlab="log10(ave # of UMI)")
par(mar=c(5,4,1,1))

saveRDS(sce,"post_gene_filter.rds")
# To load image
# sce = readRDS("post_gene_filter.rds")
```

## Normalization
A simple solution for normalization and stablizing expression varaince across genes is to tranform the count data by log(count/size.factor + 1). One may calcualte size.factor per cell as the total number of UMIs, and this assumes the total expression are the same across all the cells. However, the total expression of each cell may vary with respect to cell type and/or cell size, and the ```computeSumFactors``` function in R package scran provides a more  sophisicated way to calcualte size.factor to allow such variaation across cells [@lun2016pooling]. ```computeSumFactors``` can use initial clustering of cells to normalize expression within and beetween clusters.  Within a cluster, it estimates the size factor for many groups of cells so that there are more groups than cells, and then it can calcualte the size factor per cell using a lienar deconvolution system. 

As shown in the following plot, the final size factor estimation is indeed highly correlated with the naive definition by total count. 

Finally, the command ```normalize(sce)``` adds the normalized expression into the variable ```sce```.
```{r fig.width=14,fig.height=8}
min_mean = 1
date()
clusters = quickCluster(sce, min.mean=min_mean, method="igraph")
table(clusters)
date()
sce = computeSumFactors(sce, cluster=clusters, min.mean=min_mean)
date()
summary(sizeFactors(sce))

# Remove cells with negative or very small size factors
dim(sce)
sce = sce[,which(sizeFactors(sce) > 0)]
dim(sce)

par(mfrow=c(1,2), mar=c(5,4,2,1), bty="n")
smoothScatter(sce$total_counts, sizeFactors(sce), log="xy", 
	xlab="total counts", ylab="size factors")
plot(sce$total_counts, sizeFactors(sce), log="xy", 
	xlab="total counts", ylab="size factors", 
	cex=0.3, pch=20, col=rgb(0.1,0.2,0.7,0.3))
par(mfrow=c(1,1))

sce = normalize(sce)
saveRDS(sce,"post_norm.rds")
```

The link at [here](https://bioconductor.org/packages/devel/workflows/vignettes/simpleSingleCell/inst/doc/work-1-reads.html#61_using_the_deconvolution_method_to_deal_with_zero_counts) mentions the choice of setting `min.mean`.

Since the MTG dataset does not contain spikeIn transcripts, we implemented the code below similar to [here](http://bioconductor.org/packages/devel/workflows/vignettes/simpleSingleCell/inst/doc/xtra-3-var.html#32_when_spike-ins_are_unavailable).

## Dimension reduction

For dimension reduction, such as calculating PCA or performing TSNE, we should start by identifying a subset of genes with high level of biological signal relative to background (technical) noise. The ```decomposeVar``` function from R/cran is designed for this task. 
```{r fig.height=8,fig.width=8}
date()
new_trend = makeTechTrend(x=sce)
date()
fit = trendVar(sce, use.spikes=FALSE, loess.args=list(span=0.05))

par(mfrow=c(1,1), mar=c(5,4,2,1), bty="n")
plot(fit$mean, fit$vars, pch=20, col=rgb(0.1,0.2,0.7,0.6), 
	xlab="log(mean)", ylab="var")
curve(new_trend(x), col="red", lwd=2, add=TRUE)
curve(fit$trend(x), col="orange", lwd=2, add=TRUE)
legend("topright", legend=c("Poisson noise", "observed trend"), 
	lty=1, lwd=2, col=c("red", "orange"), bty="n")
```

The above function `makeTechTrend()` assumes a Poisson model and from the above plot, it is clearly not a suitable fit. So we will keep `fit` equal to the loess fit from `trendVar()` rather than setting it equal to the output from `makeTechTrend()`.

```{r fig.height = 8,fig.width = 8}
# fit$trend = new_trend
dec = decomposeVar(fit=fit)
top_dec = dec[order(dec$bio,decreasing=TRUE),]
top_dec[1:10,]
par(mfrow=c(2,2))
smart_hist(dec$bio,breaks=30,xlab="Biological Variance")
smart_hist(dec$FDR,breaks=30,xlab="FDR")
smart_hist(log10(dec$FDR + 1e-6),breaks=30,xlab="log10(FDR + 1e-6)")
par(mfrow=c(1,1))
plotExpression(sce, features=rownames(top_dec)[1:10])
```

When performing PCA, we can use all the genes or just those genes with high signal-to-noise ratio. TSNE analysis is usually based on the top PCs rather than the original gene expression data. We first perform PCA using all the genes and the function ```denoisePCA``` can automatically select the PCs based on modeling of technical noise. 

```{r fig.height = 11,fig.width = 11}
date()
sce = denoisePCA(sce,technical=fit$trend,approx=TRUE)
date()
dim(reducedDim(sce,"PCA"))

par(mfrow=c(1,1))
plot(log10(attr(reducedDim(sce), "percentVar")), xlab="PC",
     ylab="log10(Prop of variance explained)", pch=20, cex=0.6, 
     col=rgb(0.8, 0.2, 0.2, 0.5))
abline(v=ncol(reducedDim(sce,"PCA")), lty=2, col="red")

df_redDim = smart_df(sample_name = colnames(sce),reducedDim(sce, "PCA"))
rownames(df_redDim) = NULL
df_redDim$log10_total_features = colData(sce)$log10_total_features
df_redDim$sex = colData(sce)$sex
df_redDim$brain_hemisphere = colData(sce)$brain_hemisphere
df_redDim$brain_subregion = colData(sce)$brain_subregion
df_redDim$facs_sort_criteria = colData(sce)$facs_sort_criteria
df_redDim$class = colData(sce)$class
df_redDim$cluster = colData(sce)$cluster
df_redDim$cluster0 = colData(sce)$cluster0

all_vars = c("log10_total_features","sex","brain_hemisphere",
	"brain_subregion","facs_sort_criteria","class","cluster",
	"cluster0")
for(one_var in all_vars){
	print(ggplot_custom(DATA = df_redDim,
		X = "PC1",Y = "PC2",COL = one_var))
}

date()
sce = runTSNE(sce,use_dimred="PCA",perplexity=30,rand_seed=100)
date()

df_redDim = smart_df(df_redDim,reducedDim(sce,"TSNE"))
rownames(df_redDim) = NULL
names(df_redDim)[c(ncol(df_redDim)-1,ncol(df_redDim))] = paste0("TSNE",1:2)

for(one_var in all_vars){
	print(ggplot_custom(DATA = df_redDim,
		X = "TSNE1",Y = "TSNE2",COL = one_var))
}

saveRDS(list(sce=sce,dec=dec),"post_redDim_all_genes.rds")
# Note that this contains the results from PCA and TSNE with all genes
# rds = readRDS("post_redDim_all_genes.rds"); sce = rds$sce; dec = rds$dec; rm(rds)
```

Next we only select approximately the top 1000 highly variable genes for the PCA, based on tuning thresholds on `dec$bio` and `dec$FDR` from the earlier variance decomposition, and use the top 50 PCs for TSNE projection. 

```{r fig.height = 12,fig.width = 12}
library(svd)
library(Rtsne)

summary(dec$bio)
summary(dec$FDR)
dec1 = dec
dec1$bio[which(dec1$bio < 1e-8)] = 1e-8
dec1$FDR[which(dec1$FDR < 1e-100)] = 1e-100

par(mfrow=c(2,2))
smart_hist(log10(dec1$bio),breaks=100,main="",xlab="log10(bio)")
smart_hist(log10(dec1$FDR),breaks=100,main="",xlab="log10(FDR)")
smoothScatter(log10(dec1$bio),log10(dec1$FDR),xlab="log10(bio)",ylab="log10(FDR)")

summary(dec$FDR[dec$bio > 0.001])
FDR_thres = 1e-50 # 1e-10
bio_thres = 1e-1 # 1e-2
FDR_keep = dec$FDR < FDR_thres
bio_keep = dec$bio > bio_thres
table(FDR_keep,bio_keep)
w2kp = which(dec1$FDR < FDR_thres & dec1$bio > bio_thres)

# Subsetting highly variable genes for subsequent PCA and TSNE
sce_hvg = sce[w2kp,]
sce_hvg

edat = t(as.matrix(logcounts(sce_hvg)))
edat = scale(edat)
dim(edat)
edat[1:2,1:3]

date()
ppk = propack.svd(edat,neig=50)
date()
pca = t(ppk$d*t(ppk$u))
dim(pca)

df_hvg = smart_df(pca)
rownames(df_hvg) = NULL
names(df_hvg) = paste0("PC",seq(ncol(df_hvg)))
df_hvg = smart_df(sample_name = colnames(sce_hvg),df_hvg)
df_hvg$log10_total_features = colData(sce_hvg)$log10_total_features
df_hvg$sex = colData(sce_hvg)$sex
df_hvg$brain_hemisphere = colData(sce_hvg)$brain_hemisphere
df_hvg$brain_subregion = colData(sce_hvg)$brain_subregion
df_hvg$facs_sort_criteria = colData(sce_hvg)$facs_sort_criteria
df_hvg$class = colData(sce_hvg)$class
df_hvg$cluster = colData(sce_hvg)$cluster
df_hvg$cluster0 = colData(sce_hvg)$cluster0

set.seed(100)
date()
tsne = Rtsne(pca, pca = FALSE)
date()

df_tsne = smart_df(tsne$Y)
names(df_tsne) = paste0("HVG_TSNE",seq(ncol(tsne$Y)))
dim(df_tsne)
df_hvg = smart_df(df_hvg,df_tsne)
df_hvg[1:2,]

all_vars = c("log10_total_features","sex","brain_hemisphere",
	"brain_subregion","facs_sort_criteria","class","cluster",
	"cluster0")
for(one_var in all_vars){
	print(ggplot_custom(DATA = df_hvg,
		X = "PC1",Y = "PC2",COL = one_var))
	print(ggplot_custom(DATA = df_hvg,
		X = "HVG_TSNE1",Y = "HVG_TSNE2",COL = one_var))
}

reducedDims(sce_hvg) = SimpleList(PCA=pca, TSNE=tsne$Y)
sce_hvg

saveRDS(list(sce_hvg=sce_hvg,df_hvg=df_hvg),"post_redDim_HVG.rds")
```

## Clustering

### Kmeans
There are many methods for clustering of single cell RNA-seq data. The performance of each method may also depend on pre-processing steps, such as performing imputation or not. We will compare these methods in a seperate document. Here we just illustrate the clustering results using a simple kmeans method on the top 50 PCs. 

```{r fig.height = 12,fig.width = 12}
all_num_clust = c(5:10,15:20,25:30)
df_hvg = df_hvg[,!grepl("^KM_",names(df_hvg))]
for(num_clust in all_num_clust){
	cat(paste0("KM with ",num_clust," clusters.\n"))
	kmeans_out = kmeans(reducedDim(sce_hvg,"PCA"),centers = num_clust,
		iter.max = 5e2,algorithm = "MacQueen")
	df_hvg = smart_df(df_hvg,VV = as.factor(kmeans_out$cluster))
	names(df_hvg)[ncol(df_hvg)] = paste0("KM_",num_clust)
	print(ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",
		Y = "HVG_TSNE2",COL = paste0("KM_",num_clust)))
}

# Save temp image
saveRDS(list(sce_hvg=sce_hvg,df_hvg=df_hvg),"post_HVG_kmeans.rds")

```

### SC3
Code used here is based on [this link](https://bioconductor.org/packages/devel/bioc/vignettes/SC3/inst/doc/SC3.html#run-sc3).

```{r fig.height = 12,fig.width = 12}
library(SC3)
rowData(sce_hvg)$feature_symbol = rowData(sce_hvg)$gene
date()
all_ks = c(5,10,15)
# all_ks = 10
sce_hvg = sc3(sce_hvg,ks = all_ks,biology = TRUE,
	n_cores = num_cores,rand_seed = 100,svm_num_cells = 2000)
warnings()
date()

# Run SVM and predict labels of all other cells
date()
sce_hvg = sc3_run_svm(sce_hvg,ks = all_ks)
date()

saveRDS(list(sce_hvg=sce_hvg,all_ks=all_ks),"post_HVG_sc3.rds")
# rds = readRDS("post_HVG_sc3.rds"); sce_hvg = rds$sce_hvg; all_ks = rds$all_ks; rm(rds)

# Combine older results with SC3 results and plot HVG_TSNE vs. SC3 results
for(one_ks in all_ks){
	df_hvg$VV = as.factor(colData(sce_hvg)[,paste0("sc3_",one_ks,"_clusters")])
	names(df_hvg)[names(df_hvg) == "VV"] = paste0("SC3_",one_ks)
	print(ggplot_custom(DATA = df_hvg,X = "HVG_TSNE1",
		Y = "HVG_TSNE2",COL = paste0("SC3_",one_ks)))
}

# SC3 Plotting
all_vars = c("log10_total_features","sex","brain_hemisphere",
	"brain_subregion","facs_sort_criteria","class","cluster0")
for(one_ks in all_ks){
	# one_ks = all_ks[1]
	cat(paste0("Num Clusters = ",one_ks,"\n"))
	plotPCA(sce_hvg,
		colour_by = paste0("sc3_",one_ks,"_clusters"), 
		size_by = paste0("sc3_",one_ks,"_log2_outlier_score"))

	sc3_plot_consensus(sce_hvg,k = one_ks,
		show_pdata = c(all_vars,
		paste0("sc3_",one_ks,"_clusters"), 
		paste0("sc3_",one_ks,"_log2_outlier_score")))

	# sc3_plot_silhouette(sce_hvg, k = one_ks)

	sc3_plot_expression(sce_hvg, k = one_ks,
		show_pdata = c(all_vars,
		paste0("sc3_",one_ks,"_clusters"), 
		paste0("sc3_",one_ks,"_log2_outlier_score")))

	sc3_plot_cluster_stability(sce_hvg, k = one_ks)

	#sc3_plot_de_genes(sce_hvg, k = one_ks, 
	#	show_pdata = c(all_vars,
	#	paste0("sc3_",one_ks,"_clusters"), 
	#	paste0("sc3_",one_ks,"_log2_outlier_score")))

	sc3_plot_markers(sce_hvg, k = one_ks, 
		show_pdata = c(all_vars,
		paste0("sc3_",one_ks,"_clusters"), 
		paste0("sc3_",one_ks,"_log2_outlier_score")))
  
}

```

Finally we save the sce object, sce_hvg object, and the clustering results.
```{r}
saveRDS(sce,"final_sce.rds")
saveRDS(sce_hvg,"final_sce_hvg.rds")
saveRDS(df_hvg,"final_hvg_clust.rds")
```

# Session information
```{r}
sessionInfo()
```

# Reference

