---
title: "Workflow for single cell RNA-seq data analysis: DroNc-seq Dataset"
author: "Paul Little"
date: "`r Sys.Date()`"
bibliography: [dronc_seq.bib]
biblio-style: apalike
output: 
  html_document:
    theme: journal
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This markdown is for analyzing the [Habib et al. 2017 DroNc dataset](https://www.nature.com/articles/nmeth.4407).

# Obtaining/Loading Counts

The dataset is available [here](https://storage.googleapis.com/gtex_additional_datasets/single_cell_data/GTEx_droncseq_hip_pcf.tar).

```{r}
rm(list=ls())
where_file = c("mycomp","longleaf","remote")[2]
if(where_file == "mycomp"){
  drive = strsplit(getwd(),"/")[[1]][1]
  # src_dir = file.path(drive,"Files to KEEP/SOURCE_files")
  data_dir = file.path(drive,"Files to KEEP/BIOS_eQTL/documents/dronc_seq")
} else if(where_file == "longleaf"){
  data_dir = "/pine/scr/p/l/pllittle/CS_eQTL/s3_Real/original/DroNc/GTEx_droncseq_hip_pcf"
  # src_dir = system("echo $HOME",intern = TRUE)
} else if(where_file == "remote"){
  data_dir = "C:/Users/pllittle/Downloads/dronc_seq"
}

# Source/Libraries
source("https://bioconductor.org/biocLite.R")
# biocLite("BiocUpgrade")
bio_packs = c("SingleCellExperiment","DropletUtils","biomaRt",
              "scater","scran","limma","org.Hs.eg.db")#,"SC3")
if( !all(bio_packs %in% installed.packages()[,"Package"]) ){
  biocLite(bio_packs,suppressUpdates = TRUE)
  # biocLite("SC3",suppressUpdates = TRUE)
}
cran_packs = c("stringi","irlba")
if( !all(cran_packs %in% installed.packages()[,"Package"]) ){
  install.packages(cran_packs)
}
# DropletUtils: provides functions for data from droplet technologies such as 10X Genomics
# biomaRt: provides easy access to databases, such as Ensembl, COSMIC, Uniprot, HGNC, etc.
# scater: collection of tools for doing quality control analyses of scRNA-seq
# scran: methods provide normalization of cell-specific biases, correcting batch effects, identify marker genes
suppressPackageStartupMessages(library(SingleCellExperiment))
suppressPackageStartupMessages(library(DropletUtils))
suppressPackageStartupMessages(library(biomaRt))
suppressPackageStartupMessages(library(scater))
suppressPackageStartupMessages(library(scran))
suppressPackageStartupMessages(library(limma))

# Import counts
counts_fn = file.path(data_dir,"image.rds")
if( !file.exists(counts_fn) ){
  num_lines = 32112
  counts = read.delim(file.path(data_dir,"GTEx_droncseq_hip_pcf.umi_counts.txt"),
    sep='\t',header=TRUE,row.names = 1,check.names = FALSE,nrows = num_lines-1)
  print(dim(counts))
  saveRDS(counts,counts_fn)
}
counts = readRDS(counts_fn)
sce = SingleCellExperiment(assays = list(counts = as.matrix(counts)))
rm(counts)
sce

# Define spikes
grep("^ERCC",rownames(sce))
rownames(sce)[grep("^ERCC",rownames(sce))]
# isSpike(sce,"ERCC") = grepl("^ERCC",rownames(sce))
# sce = calculateQCMetrics(sce,feature_control=list(ERCC=is_spike))
```

# Pre-processing: Quality Control, Gene Detection, Normalization

## Gene Annotation
```{r eval=FALSE}
# Code from Dr. Sun's Rmd
anno.file = "~/research/scRNAseq/workflow/data/gene.annoation.rds"
if(file.exists(anno.file)){
  gene.annotation = readRDS(anno.file)
}else{
  ensembl = useMart("ensembl",dataset="hsapiens_gene_ensembl")
  
  attr.string = c('ensembl_gene_id', 'hgnc_symbol', 'chromosome_name')
  attr.string = c(attr.string, 'start_position', 'end_position', 'strand')
  attr.string = c(attr.string, 'description', 'percentage_gene_gc_content')
  attr.string = c(attr.string, 'gene_biotype')
  
  rowData(sce)[1:2,]
  gene.annotation = getBM(attributes=attr.string, 
                          filters =  'ensembl_gene_id', 
                          values = rowData(sce)$ID, 
                          mart = ensembl)
}

dim(gene.annotation)
```

```{r}
# My attempt to annotate gene symbols with ensembl
# ensembl = useMart("ensembl",dataset="hsapiens_gene_ensembl")
ensembl = useEnsembl(biomart="ensembl",GRCh=37,dataset="hsapiens_gene_ensembl")
attr_string = c("hgnc_symbol","external_gene_name","chromosome_name",
            "start_position","end_position","strand","description",
            "percentage_gene_gc_content","gene_biotype")
gene_anno = getBM(attributes = attr_string,
                  filters = "external_gene_name",
                  values = rownames(sce),
                  mart = ensembl)

# Check the sources of annotation discrepancy
dim(sce); dim(gene_anno)

gene_missing = setdiff(rownames(sce),gene_anno$external_gene_name)
gene_missing[1:10]
length(gene_missing)

gene_anno[which(!(gene_anno$external_gene_name %in% rownames(sce))),]
gene_anno = gene_anno[which(gene_anno$external_gene_name %in% rownames(sce)),]
dim(sce); dim(gene_anno)
table(gene_anno$chromosome_name)
# gene_anno = gene_anno[which(gene_anno$chromosome_name %in% c(1:22,"X","Y","MT")),]
# dim(sce); dim(gene_anno)
t1 = table(gene_anno$external_gene_name)
t2 = t1[t1 > 1]
length(t2)
t2[1:10]
gene_anno[which(gene_anno$external_gene_name %in% names(t2)[1:5]),]
gene_anno = dplyr::distinct(gene_anno,external_gene_name,.keep_all = TRUE)

if(FALSE){ # Old code
t1 = table(gene_anno$hgnc_symbol)
t2 = t1[t1 > 1]
t2
gene_anno[which(gene_anno$hgnc_symbol %in% names(t2)),]
gene_anno = dplyr::distinct(gene_anno,hgnc_symbol,.keep_all = TRUE)
}

dim(gene_anno)
table(gene_anno$gene_biotype)
gene_missing = setdiff(rownames(sce),gene_anno$external_gene_name)
gene_missing[1:10]
length(gene_missing)

# Subset out genes without annotation
w2kp = match(gene_anno$external_gene_name,rownames(sce))
any(is.na(w2kp))
gene_anno$external_gene_name[which(is.na(w2kp))]
sce = sce[w2kp,]
dim(sce)
rowData(sce) = gene_anno

```


## Identify Low quality cells
Look [here](https://bioconductor.org/packages/release/workflows/vignettes/simpleSingleCell/inst/doc/work-3-tenx.html#calling-cells-from-empty-droplets) for reference.
```{r fig.height=5,fig.width=5, eval=FALSE, echo=FALSE}
# Calling cells from empty droplets
bcrank = barcodeRanks(counts(sce))
# Only showing unique points for plotting speed.
uniq = !duplicated(bcrank$rank)

par(mar=c(5,4,2,1), bty="n")
plot(bcrank$rank[uniq], bcrank$total[uniq], log="xy", 
     xlab="Rank", ylab="Total UMI count", cex=0.5, cex.lab=1.2)

abline(h=bcrank$inflection, col="darkgreen", lty=2,lwd=2)
abline(h=bcrank$knee, col="dodgerblue", lty=2,lwd=2)

legend("left", legend=c("Inflection", "Knee"), bty="n", 
       col=c("darkgreen", "dodgerblue"), lty=2, cex=1.2,lwd=2)

bcrank$inflection
bcrank$knee

summary(bcrank$total)
table(bcrank$total >= bcrank$knee)
table(bcrank$total >= bcrank$inflection)

set.seed(100)
e.out = emptyDrops(counts(sce))
e.out
is.cell = (e.out$FDR <= 0.01)

```

```{r fig.asp = .5, eval=FALSE, echo=FALSE}
# Didn't run this code because all the logProb's are NaN
par(mar=c(5,4,1,1), mfrow=c(1,2), bty="n")
plot(e.out$Total, -e.out$LogProb, col=ifelse(is.cell, "red", "black"),
    xlab="Total UMI count", ylab="-Log Probability", cex=0.2)
abline(v = bcrank$inflection, col="darkgreen")
abline(v = bcrank$knee, col="dodgerblue")
legend("bottomright", legend=c("Inflection", "Knee"), bty="n", 
       col=c("darkgreen", "dodgerblue"), lty=1, cex=1.2)

plot(e.out$Total, -e.out$LogProb, col=ifelse(is.cell, "red", "black"),
    xlab="Total UMI count", ylab="-Log Probability", cex=0.2, xlim=c(0,2000), ylim=c(0,2000))
abline(v = bcrank$inflection, col="darkgreen")
abline(v = bcrank$knee, col="dodgerblue")
```

<!--- From the above analysis, some cells with very small number of UMI's may also have small FDR suggesting the distribution of UMI counts are different from what is expected from ambient profile. We choose a more conservative strategy, to keep the cells with total number of UMI larger than the inflection point estimate (bcrank\$inflection=```bcrank$inflection```) and FDR < 0.01.) -->

```{r eval=FALSE, echo=FALSE}
table(colnames(sce) == rownames(e.out))
table(e.out$FDR <= 0.01, useNA="ifany")
table(e.out$FDR <= 0.01, e.out$Total >= bcrank$inflection)
w2kp = which(e.out$FDR <= 0.01 & e.out$Total >= bcrank$inflection)
sce = sce[,w2kp]
dim(sce)

```

Next step we apply more QC based on a set of features per cell. We'll look at ribosomal genes. The imported file can be found [here](https://www.genenames.org/cgi-bin/genefamilies/set/1054/download/branch).

```{r fig.asp = 1, warning = FALSE, message = FALSE}
file_link = "https://www.genenames.org/cgi-bin/genefamilies/set/1054/download/branch"
file_name = strsplit(file_link,"/")[[1]]
file_name = file_name[length(file_name)]
ribo_fn = file.path(data_dir,file_name)
if( !file.exists(ribo_fn) ){
  cmd = sprintf("cd %s; wget %s",data_dir,file_link)
  print(cmd)
  system(cmd)
}

ribo = read.table(ribo_fn,sep='\t',header=TRUE,stringsAsFactors = FALSE)
ribo[1:2,]

# Temp save image
tmp_rds_fn = file.path(data_dir,"tmp_sce_ribo.rds")
if(where_file == "longleaf"){
  saveRDS(list(sce=sce,ribo=ribo),tmp_rds_fn)
} else if(where_file == "mycomp"){
  rds = readRDS(tmp_rds_fn)
  sce = rds$sce
  ribo = rds$ribo
  rm(rds)
}

is_mito = which(rowData(sce)$chromosome_name == "MT")
is_ribo = which(rowData(sce)$hgnc_symbol %in% ribo$Approved.Symbol)
length(is_mito)
length(is_ribo)

sce = calculateQCMetrics(sce, feature_controls=list(Mt=is_mito, Ri=is_ribo))
sort(colnames(colData(sce)))

par(mfrow=c(2,2), mar=c(5, 4, 1, 1), bty="n")
hist(log10(sce$total_counts), xlab="log10(Library sizes)", main="", 
    breaks=20, col="grey80", ylab="Number of cells")

hist(log10(sce$total_features), xlab="log10(# of expressed genes)", 
     main="", breaks=20, col="grey80", ylab="Number of cells")

hist(sce$pct_counts_Ri, xlab="Ribosome prop. (%)",
    ylab="Number of cells", breaks=40, main="", col="grey80")

hist(sce$pct_counts_Mt, xlab="Mitochondrial prop. (%)", 
    ylab="Number of cells", breaks=80, main="", col="grey80")

par(mfrow=c(2,2), mar=c(5, 4, 1, 1), bty="n")
smoothScatter(log10(sce$total_counts), log10(sce$total_features), 
     xlab="log10(Library sizes)", ylab="log10(# of expressed genes)", 
     nrpoints=500, cex=0.5)
smoothScatter(log10(sce$total_counts), sce$pct_counts_Ri, 
     xlab="log10(Library sizes)", ylab="Ribosome prop. (%)",
     nrpoints=500, cex=0.5)
# abline(h=10,  lty=1)

smoothScatter(log10(sce$total_counts), sce$pct_counts_Mt, 
     xlab="log10(Library sizes)", ylab="Mitochondrial prop. (%)",
     nrpoints=500, cex=0.5)
# abline(h=5,  lty=1)

smoothScatter(sce$pct_counts_Ri, sce$pct_counts_Mt, 
     xlab="Ribosome prop. (%)", ylab="Mitochondrial prop. (%)",
     nrpoints=500, cex=0.5)
# abline(h=5,  lty=1)
# abline(v=10, lty=1)

par(mfrow=c(2,1))
hist(sce$pct_counts_Ri,breaks=40,col="gray")
hist(sce$pct_counts_Mt,breaks=40,col="gray")
par(mfrow=c(1,1))

plot(x=sce$pct_counts_Ri,y=sce$pct_counts_Mt,pch=16,col=rgb(0,0,0,0.4))
# abline(v=10,lty=2); abline(h=5,lty=2)

table(sce$pct_counts_Mt < 5, sce$pct_counts_Ri < 10)
sce = sce[,which(sce$pct_counts_Mt < 5 | sce$pct_counts_Ri < 10)]
# sce = sce[,which(sce$pct_counts_Mt < 5 & sce$pct_counts_Ri < 10)]
dim(sce)

```

## Summarize gene level information
```{r warning = FALSE, message = FALSE, fig.height=5,fig.width=8}

rowData(sce)[1:2,]
min(rowData(sce)$mean_counts)
min(rowData(sce)$mean_counts[rowData(sce)$mean_counts>0])
min(rowData(sce)$n_cells_counts)

par(mfrow=c(1,3), mar=c(5,4,1,1))
hist(log10(rowData(sce)$mean_counts+1e-6), col="grey80",  main="", 
     breaks=40, xlab="log10(ave # of UMI + 1e-6)")
hist(log10(rowData(sce)$n_cells_counts+1), col="grey80", main="", 
     breaks=40, xlab="log10(# of expressed cells + 1)")
smoothScatter(log10(rowData(sce)$mean_counts+1e-6), 
              log10(rowData(sce)$n_cells_counts + 1), 
              xlab="log10(ave # of UMI + 1e-6)", 
              ylab="log10(# of expressed cells + 1)")
par(mfrow=c(1,1))

tb1 = table(rowData(sce)$n_cells_counts)
tb1[1:11]

```

We remove those genes that are expressed in zero or only one cell. The variable _strand_ need to be renamed, otherwise there is an error message that such a variabel name cannot be used. 

```{r}
names(rowData(sce))[6] = "strand_n"

rowData(sce)$n_cell_count_filter = rowData(sce)$n_cells_counts > 1
table(rowData(sce)$n_cell_count_filter)

# New code based on paper's methods
rowData(sce)$gene_detect_filter = apply(counts(sce),1,function(xx) length(xx[xx >= 2]) >= 10)
table(rowData(sce)$gene_detect_filter)

# sce = sce[which(rowData(sce)$n_cell_count_filter == TRUE),] # less stringent gene filter
sce = sce[which(rowData(sce)$gene_detect_filter == TRUE),] # more stringent gene filter
dim(sce)

```

Next we check those highly expressed genes 
```{r fig.asp=1}
par(mar=c(5,4,1,1))
od1 = order(rowData(sce)$mean_counts, decreasing = TRUE)
barplot(rowData(sce)$mean_counts[od1[20:1]], las=1, 
        names.arg=rowData(sce)$hgnc_symbol[od1[20:1]], 
        horiz=TRUE, cex.names=0.8, cex.axis=0.8, 
        xlab="ave # of UMI")
```



## Normalization
A simple solution for normalization and stablizing expression varaince across genes is to tranform the count data by log(count/size.factor + 1). One may calcualte size.factor per cell as the total number of UMIs, and this assumes the total expression are the same across all the cells. However, the total expression of each cell may vary with respect to cell type and/or cell size, and the ```computeSumFactors``` function in R package scran provides a more  sophisicated way to calcualte size.factor to allow such variaation across cells [@lun2016pooling]. ```computeSumFactors``` can use initial clustering of cells to normalize expression within and beetween clusters.  Within a cluster, it estimates the size factor for many groups of cells so that there are more groups than cells, and then it can calcualte the size factor per cell using a lienar deconvolution system. 

As shown in the following plot, the final size factor estimation is indeed highly correlated with the naive definition by total count. 

Finally, the command ```normalize(sce)``` adds the normalized expression into the variable ```sce```.
```{r warning = FALSE, message = FALSE}

date()
clusters = quickCluster(sce, min.mean=0.1, method="igraph")
table(clusters)
date()
sce = computeSumFactors(sce, cluster=clusters, min.mean=0.1)
date()
summary(sizeFactors(sce))
# hist(sizeFactors(sce),breaks=50,col="gray")

# Remove cells with negative or very small size factors
dim(sce)
sce = sce[,which(sizeFactors(sce) > 0)]
dim(sce)

par(mfrow=c(1,2), mar=c(5,4,2,1), bty="n")
smoothScatter(sce$total_counts, sizeFactors(sce), log="xy", 
              xlab="total counts", ylab="size factors")
plot(sce$total_counts, sizeFactors(sce), log="xy", 
     xlab="total counts", ylab="size factors", 
     cex=0.3, pch=20, col=rgb(0.1,0.2,0.7,0.3))

sce = normalize(sce) 
# logcounts(sce) = log2(gene_cell_count / size_factor + 1)
# now the cells are comparable with each other for dimension reduction/clustering

norm_sce_fn = file.path(data_dir,"norm_sce.rds")
if( where_file == "longleaf" ){
  saveRDS(sce,norm_sce_fn)
} else {
  sce = readRDS(norm_sce_fn)
}
```

## Dimension Reduction
For dimension reduction, such as calculating PCA or performing TSNE, we should start by identifying a subset of genes with high level of biological signal relative to background (technical) noise. The ```decomposeVar``` function from R/cran is designed for this task. 

```{r warning = FALSE, message = FALSE, fig.height=5,fig.width=5}

new.trend = makeTechTrend(x=sce)
fit = trendVar(sce, use.spikes=FALSE, loess.args=list(span=0.05))

par(mfrow=c(1,1), mar=c(5,4,2,1), bty="n")
plot(fit$mean, fit$var, pch=20, col=rgb(0.1,0.2,0.7,0.6), 
     xlab="log(mean)", ylab="var")
curve(fit$trend(x), col="orange", lwd=2, add=TRUE)
curve(new.trend(x), col="red", lwd=2, add=TRUE)
legend("top", legend=c("Poisson noise", "observed trend"), 
       lty=1, lwd=2, col=c("red", "orange"), bty="n")

fit$trend = new.trend
dec = decomposeVar(fit=fit) # obtain bio, FDR, pvalues for testing for HVGs (highly variable genes)
top.dec = dec[order(dec$bio, decreasing=TRUE),]
plotExpression(sce, features=rownames(top.dec)[1:10])
```

```{r echo=FALSE,eval=FALSE}
# Simulate example to understand variance decomposition

set.seed(100)

nspikes <- ncells <- 100
spike.means <- 2^runif(nspikes, 3, 8)
spike.disp <- 100/spike.means + 0.5
spike.data <- matrix(rnbinom(nspikes*ncells, mu=spike.means, size=1/spike.disp), ncol=ncells)

ngenes <- 10000
cell.means <- 2^runif(ngenes, 2, 10)
cell.disp <- 100/cell.means + 0.5
cell.data <- matrix(rnbinom(ngenes*ncells, mu=cell.means, size=1/cell.disp), ncol=ncells)

combined <- rbind(cell.data, spike.data)
colnames(combined) <- seq_len(ncells)
rownames(combined) <- seq_len(nrow(combined))
y <- SingleCellExperiment(assays = list(counts=combined))
isSpike(y) <- rep(c(FALSE, TRUE), c(ngenes, nspikes))

# Normalizing.
y <- computeSpikeFactors(y) # or computeSumFactors
y <- normalize(y)

# Decomposing technical and biological noise.
fit <- trendVar(y)
results <- decomposeVar(y, fit)
  plot(results$mean, results$total)
  o <- order(results$mean)
  lines(results$mean[o], results$tech[o], col="red", lwd=2)

  plot(results$mean, results$bio)
```

When performing PCA, we can use all the genes or just those genes with high signal-to-noise ratio. TSNE analysis is usually based on the top PCs rather than the original gene expression data. We first perform PCA using all the genes and the function ```denoisePCA``` can automatically select the PCs based on modeling of technical noise. 

```{r warning = FALSE, message = FALSE, fig.height=8,fig.width=11}
date()
# This will basically objectively select the appropriate number of PCs
sce = denoisePCA(sce, technical=new.trend, approx=TRUE)
date()
dim(reducedDim(sce, "PCA"))

plot(log10(attr(reducedDim(sce), "percentVar")), xlab="PC",
     ylab="log10(Prop of variance explained)", pch=20, cex=0.6, 
     col=rgb(0.8, 0.2, 0.2, 0.5))
abline(v=ncol(reducedDim(sce, "PCA")), lty=2, col="red")

df_pcs = data.frame(reducedDim(sce, "PCA"))
df_pcs$log10_total_features = colData(sce)$log10_total_features
df_pcs$part_cell_id = sapply(colnames(sce),function(xx) 
  strsplit(xx,"_")[[1]][1],USE.NAMES=FALSE)

gp1 = ggplot(df_pcs, aes(PC1,PC2,col=log10_total_features)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp1

range(df_pcs$PC1)
range(df_pcs$PC2)
table(df_pcs$part_cell_id)
table(df_pcs$part_cell_id[which(df_pcs$PC1 >= 25)])

gp2 = ggplot(df_pcs, aes(PC1,PC2,col=part_cell_id)) + 
  geom_point(size=0.5,alpha=0.6) + theme_classic() +
  guides(color = guide_legend(override.aes = list(size=3)))
gp2


date()
sce = runTSNE(sce, use_dimred="PCA", perplexity=30, rand_seed=100)
date()

df_tsne = data.frame(reducedDim(sce, "TSNE"))
df_tsne$log10_total_features = colData(sce)$log10_total_features
df_tsne$part_cell_id = sapply(rownames(df_pcs),function(xx) 
  strsplit(xx,"_")[[1]][1],USE.NAMES=FALSE)

gp1 = ggplot(df_tsne, aes(X1,X2,col=log10_total_features)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp1

gp2 = ggplot(df_tsne, aes(X1,X2,col=part_cell_id)) + 
  geom_point(size=0.5,alpha=0.6) + theme_classic() + 
  # scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp2

# Output rds post initial dimension reduction
DR_sce_fn = file.path(data_dir,"DR_sce.rds")
if( where_file == "longleaf" ){
  saveRDS(list(sce=sce,dec=dec),DR_sce_fn)
} else {
  rds = readRDS(DR_sce_fn)
  sce = rds$sce
  dec = rds$dec
  rm(rds)
}
```

Next we only select around top 1000 genes for the PCA and use the top 50 PCs for TSNE projection. 

```{r warning = FALSE, message = FALSE, fig.asp = 0.8}


library(svd)
library(Rtsne)

summary(dec$bio)
dec1 = dec
dec1$bio[which(dec$bio < 1e-8)] = 1e-8
dec1$FDR[which(dec$FDR < 1e-100)] = 1e-100

par(mfrow=c(1,2))
hist(log10(dec1$bio), breaks=100, main="")
hist(log10(dec1$FDR), breaks=100, main="")

summary(dec$FDR[dec$bio > 0.001])
table(dec$FDR < 1e-10, dec$bio > 0.01)

# Subsetting genes based on FDR and biological residual thresholds
w2kp = which(dec$FDR < 1e-10 & dec$bio > 0.01)
sce_sub = sce[w2kp,]
sce_sub

# Extracting log2(norm_express+1), transposing, scaling columns(genes) to have mean = 0, var = 1
edat = t(as.matrix(logcounts(sce_sub)))
edat = scale(edat)
dim(edat)
edat[1:2,1:3]

# Perform SVD on sce_sub
date()
ppk = propack.svd(edat,neig=50)
date()
pca = t(ppk$d*t(ppk$u)) # calculates pc scores aka principal components

df_pcs = data.frame(pca)
df_pcs$log10_total_features = colData(sce_sub)$log10_total_features
df_pcs$part_cell_id = sapply(colnames(sce_sub),function(xx) 
  strsplit(xx,"_")[[1]][1],USE.NAMES=FALSE)
df_pcs[1:2,]

gp1 = ggplot(df_pcs, aes(X1,X2,col=log10_total_features)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp1

gp2 = ggplot(df_pcs, aes(X1,X2,col=part_cell_id)) + 
  geom_point(size=0.5,alpha=0.6) + theme_classic() + 
  # scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp2

set.seed(100)
date()
tsne = Rtsne(pca, pca = FALSE)
date()


df_tsne = data.frame(tsne$Y)
df_tsne$log10_total_features = colData(sce_sub)$log10_total_features
df_tsne$part_cell_id = sapply(colnames(sce_sub),function(xx) 
  strsplit(xx,"_")[[1]][1],USE.NAMES=FALSE)
dim(df_tsne)
df_tsne[1:2,]

gp1 = ggplot(df_tsne, aes(X1,X2,col=log10_total_features)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp1

gp2 = ggplot(df_tsne, aes(X1,X2,col=part_cell_id)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  # scale_colour_gradient(low="lightblue",high="red") +
  guides(color = guide_legend(override.aes = list(size=3)))
gp2

reducedDims(sce_sub) = SimpleList(PCA=pca, TSNE=tsne$Y)
sce_sub
```

## Clustering
There are many methods for clustering of single cell RNA-seq data. The performance of each method may also depend on pre-processing steps, such as performing imputation or not. We wil compare these methods in a seperate document. Here we just illustrate the clustering reuslts using a simple kmeans method on the top 50 PCs. 

```{r warning = FALSE, message = FALSE, fig.asp = 1}

k10_50_pcs = kmeans(reducedDim(sce_sub, "PCA"), centers=10, 
                    iter.max=150, algorithm="MacQueen")
names(k10_50_pcs)
dim(k10_50_pcs$centers)

df_tsne$cluster_kmean = as.factor(k10_50_pcs$cluster)
cols = c("#FB9A99","#FF7F00","yellow","orchid","grey",
         "red","dodgerblue2","tan4","green4","#99c9fb")

gp1 = ggplot(df_tsne, aes(X1,X2,col=cluster_kmean)) + 
  geom_point(size=0.2,alpha=0.6) + theme_classic() + 
  scale_color_manual(values=cols) + 
  guides(color = guide_legend(override.aes = list(size=3)))
gp1

```

## Output Post-Clustering Image
```{r}
# Temp save image
post_rds_fn = file.path(data_dir,"post_cluster.rds")
if(where_file == "longleaf"){
  saveRDS(list(sce=sce,sce_sub=sce_sub,
    k10_50_pcs=k10_50_pcs,df_tsne=df_tsne),
    post_rds_fn)
} else if(where_file == "mycomp"){
  rds = readRDS(post_rds_fn)
  sce = rds$sce
  sce_sub = rds$sce_sub
  k10_50_pcs = rds$k10_50_pcs
  df_tsne = rds$df_tsne
  rm(rds)
}

```


## Compare paper's clustering to ours
Check if paper supplement cluster is consistent with our results, check how many genes the paper have left
```{r}
src_dir = system("echo $HOME",intern = TRUE)
source(file.path(src_dir,"SOURCE.R"))

tmp_lab = smart_RT(file.path(data_dir,"cluster_num_label.txt"),sep = "\t",header = TRUE)
tmp_lab = name_change(tmp_lab,"Name","Cluster.Name")
tmp_lab = name_change(tmp_lab,"Name.1","Cell_Type")

tmp_res = smart_RT(file.path(data_dir,"paper_cluster_res.txt"),sep = "\t",header = TRUE,comment.char = "")
tmp_res = smart_merge(tmp_res,tmp_lab[,c("Cluster.Name","Cell_Type")],all.x=TRUE)

table(tmp_res[,c("Cluster.ID","Cluster.Name")])
range(tmp_res$X.Genes)
hist(tmp_res$X.Genes,breaks=50,col="gray")
df_tsne$Cell.ID = colnames(sce_sub)

# Merge and compare
blah = smart_merge(df_tsne,tmp_res)
blah[1:5,]
smart_table(blah[,c("Cell_Type","Cluster.Name")])
smart_table(blah[,c("Cell_Type","cluster_kmean")])
smart_table(blah[,c("Cluster.Name","cluster_kmean")])


```

So in the paper, they have 15 clusters (ASC1,ASC2,END,exCA1,exCA3,exDG,exPFC1,exPFC2,GABA1,GABA2,MG,NSC,ODC1,OPC, and Unclassified). Using Dr. Sun's code, we specified 10 clusters for kmeans by clustering 50 PCAs derived from filtering down to 2799 genes. 

kmeans cluster 1 seems to capture OPC well.
kmeans clusters 2 and 3 capture a mix of MG and NSC.
kmeans cluster 3 seems to capture GABA well.
kmeans cluster 4 nuclei are all considered unclassified by the paper.
kmeans cluster 5 seems to be noisy but mostly captures exPFC.
kmeans cluster 6 seems to capture ODC well, but also somewhat noisy.
kmeans cluster 7 seems to capture ASC well.
kmeans cluster 8 seems to capture END well.
kmeans cluster 9 nuclei are mostly unclassified by the paper.
kmeans cluster 10 is noisy but most samples are classified as exDG.


# Session information
```{r}
sessionInfo()
```

# Reference

