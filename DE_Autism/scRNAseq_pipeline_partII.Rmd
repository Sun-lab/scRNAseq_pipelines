---
title:  "A workflow for Defferential expression data analysis-Autism, Part II"
author: "Mengqi Zhang, Wei Sun"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: journal
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo=TRUE, cache = !TRUE, warning = FALSE, 
                      message = FALSE, cache.lazy = FALSE)
runcode=!FALSE
```

# Introduction

This markdown is for analyzing the paper [Single-cell genomics identifies cell type–specific molecular changes in autism](https://science.sciencemag.org/content/364/6441/685.abstract). Some details of their analysis is provided [here](https://science.sciencemag.org/content/suppl/2019/05/15/364.6441.685.DC1). Briefly, there analysis are doing individual case-control study based on Kullback–Leibler divergence and Jensen–Shannon divergence on the gene differential expression analysis of certain cell type and compared the result with the [MAST](https://www.bioconductor.org/packages/release/bioc/html/MAST.html) packages(for scRNAseq) and the [DESeq2](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html) packages(for bulk RNAseq)

This is part II of the whole workflow of defferential expression data analysis-Autism. In part I, we do some basic data cleaning and processing. Then we take the first 3K genes who expressed in the most cells, and we randomly take 10 percentage of the single cells among all cells in the dataset. After this step, the data was denoised with [DCA](https://github.com/theislab/dca) package, a software to denoise the scRNAseq counts with autoencoder, an artificial neural network used to learn efficient data codings in an unsupervised manner.The input rawM3k10.csv includes a CSV/TSV-formatted raw count matrix with genes in rows and cells in columns.

```{bash dca_comments,eval=!runcode}
dca rawM3k10.csv res_dca_rawM3k10/
```


The output of DCA is an estimation of the expression of each gene and each cell in an ZINB distribution, which includes the estimation of the mean, dropout probabilities and dispersion for each cell and gene as an the ZINB distribution. This pipeline will start from these estimation. 

Note: DCA itself includes the size factor of each cells in its pipelines.Thus the input of DCA should be the raw count data without any normalization or log transformation.

The packages required for the analysis are as follows:

 - MASS: Tools for basic statistical calculation.
 - emdbook: Tools for fitting and simulating zero-inflated negative binomial(ZINB) distribution.

 - moments: Tools support MAST.
 - MAST: Tools for scRNAseq differential expression analysis.
 - lme4: Tools support MAST.
 - DESeq2: Tools for bulk RNAseq differential expression analysis.

# initial setup

R packages required in this pipeline:
```{r load_libraries,eval=runcode}
library("MASS")
library("emdbook")
library("moments")
library("MAST")
library("lme4")
library("DESeq2")
```

#functions in our analysis

R packages required in this pipeline:
```{r load_functions,eval=runcode}
function_dir="/fh/fast/sun_w/mengqi/1.Testing_scRNAseq/Command/"

source(paste0(function_dir,"7.0_ZINB_fit_functions.R"))
source(paste0(function_dir,"8.0_kl_divergence_functions.R"))
source(paste0(function_dir,"9.0_Fstat_functions.R"))

```

#Data Preparation

## Basic settings
```{r basic_settings,eval=runcode}

#data directory
dca_dir="/fh/fast/sun_w/mengqi/Data_PRJNA434002/res_dca_rawM3k10/"
data_dir="/fh/fast/sun_w/mengqi/Data_PRJNA434002/"

#clusters provide the cluster type of the data, in current settings we take the first cluster
cluster_tag=1

#sim_n is number of reconstructed gene expressions counts for each gene and each cell based on the parameters of DCA.
sim_n=10

covariate_flag=NA #c(NA, "quantile99")


```

## phenotype data preparation
```{r load_meta,eval=runcode}
#phenotye information
t_meta = readRDS(paste0(data_dir,"meta10.rds"))

#find the cluster
cur_cluster=as.character(unique(t_meta$cluster)[cluster_tag])

```

## expression data preparation
```{r load_expression_data,eval=runcode}

# files from DCA
t_mean = read.table(paste0(dca_dir,"mean_signif4.tsv.gz"), 
                    sep = "\t", header = TRUE)

t_dispersion = read.table(paste0(dca_dir,"dispersion_signif4.tsv.gz"),
                    sep = "\t", header = TRUE)

t_dropout = read.table(paste0(dca_dir,"dropout_signif4.tsv.gz"),
                    sep = "\t", header = TRUE)

dim(t_mean)
t_mean[1:2,1:5]

dim(t_dispersion)
t_dispersion[1:2,1:5]

dim(t_dropout)
t_dropout[1:2,1:5]

```

##certain cluster data processing

```{r locate_cluster,eval=runcode}

sub_mean=as.matrix(t_mean[,t_meta$cluster==cur_cluster])

sub_dispersion=as.matrix(t_dispersion[,t_meta$cluster==cur_cluster])
sub_dropout=as.matrix(t_dropout[,t_meta$cluster==cur_cluster])

meta=t_meta[t_meta$cluster==cur_cluster,]

#generate idividual label
cur_individual=unique(meta$individual)

```


#expression data reconstruction and individual level 

With the estimated parameters from DCA, we are able to reconstruct the counts of each gene and each cell. We simulate the counts and use it as our denoised/reconstructed data in the further analysis.

After this reconstruction, we gathers all counts of each gene of each individual, and then estimate the distance between individual by estimation the distance of these distributions. Here we provide two methods one is fitting this distribution to another negative binomial distribution, another is getting the impirical distribution by calculating their densities.

##Count reconstruction and individual level ZINB fitting.
```{r count_reconstruction_fitting,eval=runcode, fig.dim = c(15,20)}

#for store count reconstruction result
sim_data=array(dim=c(nrow(sub_mean),ncol(sub_mean),sim_n),
                      dimnames = list(rownames(sub_mean),colnames(sub_mean),1:sim_n))

#for store individual level ZINB fitting result
sim_fit=array(dim=c(nrow(sub_mean),length(cur_individual),3),
                      dimnames = list(rownames(sub_mean),cur_individual,
                                      c("logmean","dispersion","dropout_rate")))

if(!is.na(covariate_flag)){
  quantile99=log(apply(sub_mean,2,function(x)return(quantile(x,0.99)+1)))
  covariate=as.matrix(quantile99)
}

op=par(mfrow = c(3, 4),pty = "s") 
for(i_g in 1:nrow(sub_mean)){
  cur_sim=matrix(ncol=sim_n,nrow=ncol(sub_mean))
  for(i_s in 1:ncol(sub_mean)){
    cur_sim[i_s,]=emdbook::rzinbinom(sim_n,sub_mean[i_g,i_s], sub_dispersion[i_g,i_s], sub_dropout[i_g,i_s])
  }
  sim_data[i_g,,]=cur_sim
  for(i_ind in 1:length(cur_individual)){
    cur_ind=cur_individual[i_ind]

    #fit sim
    cur_sim_ind=as.numeric(cur_sim[meta$individual==cur_ind,])
    
    if(!is.na(covariate_flag)){
      cur_covariate=rep(covariate[meta$individual==cur_ind,],sim_n)
      sim_fit[i_g,i_ind,]=fit_nbzinb(cur_sim_ind,cur_covariate)
    }
    if(is.na(covariate_flag)){
      sim_fit[i_g,i_ind,]=fit_nbzinb(cur_sim_ind)
    }
    
    #plot
    if(i_g<=3 & i_ind<=4){
      hist(cur_sim_ind,main=paste0("Histogram of dca, ",rownames(sub_mean)[i_g]," of ",cur_ind,", ",cur_cluster),xlab="Simulated Count", ylab = "Frequency")
    }
  }
  if(i_g%%500==0){
    print(i_g)
  }
}
par(op)

```


# Calculate the distance between each individuals
In our workflow, we provide two kind of method to estimate the distance between individuals of any given genes. The Kullback-Leibler divergence (KL divergence) and the Jensen-Shannon divergence:

suppose we have distribution P and Q
Define: M=(P+Q)/2 and D(P||Q)=-sum((P * (log(Q/P)))), then

(1)the Symmetrised Kullback-Leibler divergence:
        KLmean=1/2 * (D(P||Q)+D(Q||P))

(2)the Jensen-Shannon divergence:
        JSD=1/2 * (D(P||M)+D(Q||M))

We use dist_array to store the distance between each individuals of each genes.

##basic settings
```{r dist_array,eval=runcode}

fit_method="zinb" #fit_method = c("zinb","empirical")

dist_method="JSD" #dist_method=c("JSD","mean")

```

## Option 1: empirical method
If we fit the distribution of expression with empirical method, we calculate:
```{r empirical method,eval=runcode}

if(fit_method=="empirical"){
  dist_array=array(dim=c(nrow(sim_data),length(cur_individual),length(cur_individual)),
               dimnames = list(rownames(sim_data),cur_individual,cur_individual))
  
  for(i_g in 1:nrow(sim_data)){
  cur_sim=sim_data[i_g,,]
    for(i_ind_a in 1:length(cur_individual)){
      for(i_ind_b in 1:length(cur_individual)){
        cur_ind_a=cur_individual[i_ind_a]
        cur_ind_b=cur_individual[i_ind_b]
        #fit sim
        cur_sim_ind_a=as.numeric(cur_sim[meta$individual==cur_ind_a,])
        cur_sim_ind_b=as.numeric(cur_sim[meta$individual==cur_ind_b,])
        dist_array[i_g,i_ind_a,i_ind_b]=tryCatch(mean_KL_dens(cur_sim_ind_a,cur_sim_ind_b,alter=dist_method,fit_model=fit_method), error = function(e) {NA} )
        }
      }
    if(i_g%%500==0){
      print(i_g)
    }
  }
  dim(dist_array)
  dist_array[1,1:2,1:2]
}

```

## Option 2: individual level zinb fitting method
If we fit the distribution of expression with zinb model, we calculate:
```{r zinb method,eval=runcode}

if(fit_method=="zinb"){
  dist_array=array(dim=c(nrow(sim_fit),length(cur_individual),length(cur_individual)),
                             dimnames = list(rownames(sim_fit),cur_individual,cur_individual))

  sim_fit[,,1]=exp(sim_fit[,,1]) #change the log mean to mean!!!

  for(i_g in 1:nrow(sim_fit)){
    cur_fit=sim_fit[i_g,,]
    for(i_ind_a in 1:length(cur_individual)){
      for(i_ind_b in 1:length(cur_individual)){
        cur_a=cur_fit[i_ind_a,]
        cur_b=cur_fit[i_ind_b,]
        #kl and jsd
        dist_array[i_g,i_ind_a,i_ind_b]=tryCatch(mean_KL_dens(cur_a,cur_b,alter=dist_method,zinb.quantile=0.975,fit_model=fit_method),error = function(e) {NA} )
      }
    }
    if(i_g%%500==0){
      print(i_g)
    }
  }
  
  dim(dist_array)
  dist_array[1,1:2,1:2]

}

```

# pval calculation: manova and permanova-S method

We summary those distance and calculate case-control level comparison based on permuation method.Here we provide two methods:
(1). The [Manova](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1442-9993.2001.01070.pp.x) method developed by Anderson MJ, 2001
(2). The [Permanova-S](https://academic.oup.com/bioinformatics/article/32/17/2618/2450751) method developed by Tang ZZ et al, 2016.

## Basic Settings
```{r F_stat_param,eval=runcode}
#pheotype preparation
phenotype=matrix(1,ncol=1,nrow=length(cur_individual))
phenotype[which(meta$diagnosis[match(cur_individual,meta$individual)]=="Control")]=0

F_method="p" #c("p","ps") for Manova method or Permanova-S method

ind_covariate_flag="ind"  #c(NA, "ind") the individual level covariate for regression, only works for permanova-S method
perm_num=500              #the minimium permutation number.
tol=0.2                   #a factor for threshold settings, p-values no bigger than the threshold(tol/perm_num) will put in a senario with 10 times of permutation size than current situation.

tol_missing_dist=0 # tolerate missing p-values number, if missing numer is no bigger than it, we will make it up with median of distance.See details in next section.

tol_missing_sample=round(length(cur_individual)/2) #if effective sample less than this number, stop calculation. See details in next section.


```

## p-value calculation
We first use function cal_permanova_pval2, which is desire for array calculation for speeding. Then we give the NAs a second chance by removing missing samples/ missing distances, or fix the missing samples with median distances. 

In the first use of function cal_permanova_pval2, we start from a small permutation size, which is the minimium permutation number (e.g. perm_num=500), then we define a factor for threshold settings(tol, range from 0 to 1), p-values no bigger than the threshold(tol/perm_num) will put in a senario with 10 times of permutation size than current situation.

```{r F_stat,eval=runcode}

#set covariate
if(is.na(ind_covariate_flag)){
  covariate_model_matrix=NA
}
if(ind_covariate_flag=="ind"){
  cur_covariate=meta[match(cur_individual,meta$individual),c("age","sex","Capbatch","Seqbatch")]
  rownames(cur_covariate)=cur_individual
  covariate_model_matrix=model.matrix(~age+sex+Capbatch+Seqbatch,cur_covariate)
}

dist_pval=cal_permanova_pval2(dist_array,phenotype,Fstat_method=F_method,perm_num.min = perm_num,zm=covariate_model_matrix)
print("0 level complete")
print(Sys.time())
print(gc())
thres=tol/perm_num
second_index=which(dist_pval<thres)
if(length(second_index)>0){
  print("1st level")
  print(Sys.time())
  print(gc())
  sub_dist_array=dist_array[second_index,,,drop=FALSE]
  sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*10,Fstat_method=F_method,zm=covariate_model_matrix)
  dist_pval[second_index]=sub_dist_pval
  thres=tol/(perm_num*10)
  second_index=which(dist_pval<thres)
  if(length(second_index)>0){
    print("2nd level")
    print(Sys.time())
    print(gc())
    sub_dist_array=dist_array[second_index,,,drop=FALSE]
    sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*100,Fstat_method=F_method,zm=covariate_model_matrix)
    dist_pval[second_index]=sub_dist_pval
    thres=tol/(perm_num*100)
    second_index=which(dist_pval<thres)
    if(length(second_index)>0){
      print("3rd level")
      print(Sys.time())
      print(gc())
      sub_dist_array=dist_array[second_index,,,drop=FALSE]
      sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*1000,Fstat_method=F_method,zm=covariate_model_matrix)
      dist_pval[second_index]=sub_dist_pval
    }
  }
}


```

## p-value calculation II(OPTIONAL)
Here we give the NAs a second chance by removing missing samples/ missing distances, or fix the missing samples with median distances.We use 2 parameter to decide the qualified genes.

The tol_missing_dist is tolerate missing p-values number, if missing numer is no bigger than it, we will make it up with median of distance.See details in next section.

The tol_missing_sample is a threshold that if effective sample less than this number, stop calculation. See details in next section.
```{r F_stat_second_chance,eval=runcode}

second_index=which(is.na(dist_pval))
tol_missing_dist=0 # tolerate missing p-values number, if missing numer is no bigger than it, we will make it up with median of distance.
tol_missing_sample=dim(dist_array)[2]/2 #if effective sample less than this number, stop calculation

for(i2 in second_index){
  print(i2)
  x=dist_array[i2,,]
  #calculate zeros
  zero_sum=apply(is.na(x),2,sum)
  
  #first thres: to remove all zero inds
  flag=(zero_sum<nrow(x))
  if(sum(flag)>=tol_missing_sample){
    x=x[flag,flag]
    cur_pheno=phenotype[flag]
    
    #second thres:to remove inds with more than tolerate missing values
    zero_sum=apply(is.na(x),2,sum)
    flag=(zero_sum<=tol_missing_dist)
    if(sum(flag)>=tol_missing_sample){ 
      #third thres:to 
      x=x[flag,flag]
      cur_pheno=cur_pheno[flag]
      #add missing values:
      fill_index=which(!complete.cases(x))
      if(length(fill_index)>0){
        for(i_f in fill_index){
          for(j_f in fill_index){
            if(j_f>i_f){
              x[i_f,j_f]=median(c(x[,i_f],x[,j_f]),na.rm = TRUE) #here is a little recurrence, but that's OK...
              x[j_f,i_f]=x[i_f,j_f]
            }
          }
        }
      }
      dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = perm_num,zm=covariate_model_matrix), error = function(e) {NA} )
      thres=tol/perm_num
      if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
        dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*10),zm=covariate_model_matrix), error = function(e) {NA} )
        thres=tol/(perm_num*10)
        if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
          dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*100),zm=covariate_model_matrix), error = function(e) {NA} )
          thres=tol/(perm_num*100)
          if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
            dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*1000),zm=covariate_model_matrix), error = function(e) {NA} )
          }
        }
      }
    }
  }
}

head(dist_pval)


```


#Other method comparison
We compare our method with bulk RNAseq analysis result based on [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) package and mixed model result based on [MAST](https://www.bioconductor.org/packages/release/bioc/html/MAST.html) package.

##Data preparation for DESeq2 and MAST analysis

```{r DESeq2_MAST_pre,eval=runcode}
#individual level info
cell_num=matrix(ncol=1,nrow=length(cur_individual))
rownames(cell_num)=cur_individual
colnames(cell_num)="cell_num"
read_depth=matrix(ncol=1,nrow=length(cur_individual))
rownames(read_depth)=cur_individual
colnames(read_depth)="read_depth"

zero_rate_ind=matrix(nrow=dim(sim_data)[1],ncol=length(cur_individual))
rownames(zero_rate_ind)=dimnames(sim_data)[[1]]
colnames(zero_rate_ind)=cur_individual
sim_matrix_bulk=matrix(nrow=dim(sim_data)[1],ncol=length(cur_individual)) #for DESeq2
rownames(sim_matrix_bulk)=dimnames(sim_data)[[1]]
colnames(sim_matrix_bulk)=cur_individual

CDR=matrix(ncol=1,nrow=nrow(meta)) #for MAST
colnames(CDR)="CDR"
CDR_ind=matrix(ncol=1,nrow=length(cur_individual))
colnames(CDR_ind)="CDR_ind"

for(i_ind in 1:length(cur_individual)){
  cur_ind=cur_individual[i_ind]
  #fit org
  cur_ind_m=sim_data[,meta$individual==cur_ind,,drop=FALSE]
  cell_num[i_ind]=dim(cur_ind_m)[2]
  read_depth[i_ind]=sum(as.numeric(cur_ind_m),na.rm = TRUE)/cell_num[i_ind]*1000
  
  zero_rate_ind[,i_ind]=apply(cur_ind_m==0,1,function(x){return(sum(as.numeric(x),na.rm = TRUE))})/cell_num[i_ind]
  sim_matrix_bulk[,i_ind]=apply(cur_ind_m,1,function(x){return(sum(as.numeric(x),na.rm = TRUE))})
  
  cur_CDR=sum(cur_ind_m>0,na.rm = TRUE)/sum(cur_ind_m>-1,na.rm = TRUE)
  CDR[meta$individual==cur_ind]=cur_CDR
  CDR_ind[i_ind]=cur_CDR
}

head(zero_rate_ind)
head(read_depth)

plot(read_depth,CDR_ind)
cor(read_depth,CDR_ind)

cur_info=meta[,c("individual","diagnosis")] #for DESeq2
cur_info=unique(cur_info)
rownames(cur_info)=cur_info$individual

```


##DESeq2 analysis
we calculate bulk information by summing up raw counts of all cells(of certain cluster) of an individual within a genes using the [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) developed by M Love et al.We follow the protocol of the official [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) website to implement the differential expression analysis
```{r DESeq2_analysis,eval=runcode}
dds=DESeqDataSetFromMatrix(countData = sim_matrix_bulk,
                           colData = cur_info,
                           design = ~ diagnosis)

dds=DESeq(dds)
deseq_pval=results(dds)$pvalue
deseq_pval[1:10]

```


#MAST analysis
[MAST](https://www.bioconductor.org/packages/release/bioc/html/MAST.html)
The input of MAST analysis can be many format including matrix andSingleCellAssay.

Inputs:
(1)The log-transformed expression count matrix, with each column represents the cells and each rows represents the genes.
(2)The meta data, including cell information and individual information.

Here we both test the regular model and mixed model. We get the p-values based on the Hurdle model ("H" model)

```{r MAST_analysis_pre,eval=runcode}

meta_flat=matrix(ncol=ncol(meta),nrow=0)
for(im in 1:sim_n){
  cur_meta=meta
  cur_meta$cell=paste0(cur_meta$cell,"_",im)
  meta_flat=rbind(meta_flat,cur_meta)
}
dim(meta_flat)

sim_matrix_log=log(1 + sim_data)
dim(sim_matrix_log)=c(dim(sim_data)[1],dim(sim_data)[2]*dim(sim_data)[3])
dim(sim_matrix_log)

sim_matrix_log[1:10,1:10]
cell_id=meta_flat$cell
gene_id=dimnames(sim_data)[[1]]
rownames(sim_matrix_log)=gene_id
colnames(sim_matrix_log)=cell_id
sim_matrix_log[1:10,1:10]

library("MAST")
library("lme4")

fData=data.frame(primerid=gene_id)
cData=data.frame(wellKey=cell_id)
colnames(meta_flat)
length(fData)
length(cData)

sca=FromMatrix(sim_matrix_log, cData, fData)
colData(sca)$cngeneson = as.numeric(CDR) #from Chong and Paul
colData(sca)$diagnosis =as.factor(meta_flat$diagnosis)
colData(sca)$ind = as.factor(meta_flat$individual)

colData(sca)


date()
```

```{r MAST_zlm,eval=runcode,echo=FALSE}
b0 = zlm(formula = ~ diagnosis, sca = sca, parallel = TRUE)
b1 = zlm(formula = ~ diagnosis + ( 1 | ind ), sca = sca, method = 'glmer', 
         ebayes = FALSE, parallel = TRUE)
```

```{r MAST_break,eval=runcode}
date()

b0
b1

```

```{r MAST_lrTest,eval=runcode,echo=FALSE}
lrt0 = lrTest(b0, "diagnosis")
lrt1 = lrTest(b1, "diagnosis")
```

```{r MAST_analysis_post,eval=runcode}
date()
dim(lrt1)
lrt1[1,,]

MAST_pval0 = apply(lrt0, 1, function(x){x[3,3]})
length(MAST_pval0)
MAST_pval0[1:4]

MAST_pval1 = apply(lrt1, 1, function(x){x[3,3]})
length(MAST_pval1)
MAST_pval1[1:4]

```



#Check and Save Results

```{r save_results,eval=runcode, fig.dim = c(8,8)}
op=par(mfrow = c(2, 2), pty = "s", bty="n")

hist(dist_pval, main="Our Method", xlab="p-value")

hist(deseq_pval, main="DESeq2", xlab="p-value")

hist(MAST_pval0, main="MAST bayesglm", xlab="p-value")

hist(MAST_pval1, main="MAST glmer, mean-DE", xlab="p-value")

par(op)

df1 = data.frame(dist_pval, deseq_pval, MAST_pval0, MAST_pval1)
rownames(df1)=rownames(sub_mean)
colnames(df1)=c("dist_pval", "deseq_pval", "MAST_pval_bayesglm", "MAST_pval_glmer")
dim(df1)
df1[1:2,]

write.table(df1, paste0(data_dir,"pvals_",cluster_tag,"_3k10.txt"), append=FALSE, 
            quote=FALSE, sep="\t", row.names = FALSE, col.names = TRUE)
```


#One-time permutation
To evaluate the power and type I error. We do one time individual level case-control permuataion and calculate the p-values.

##Individual level permutation example: Our method 
```{r perm_jsd,eval=runcode }

perm_label=1

dist_pval=NA
#set perm
if(perm_label>0){
  phenotype=phenotype[sample.int(length(phenotype),length(phenotype)),drop=FALSE]
}

#our method
dist_pval=cal_permanova_pval2(dist_array,phenotype,Fstat_method=F_method,perm_num.min = perm_num,zm=covariate_model_matrix)
print("0 level complete")
print(Sys.time())
print(gc())
thres=tol/perm_num
second_index=which(dist_pval<thres)
if(length(second_index)>0){
  print("1st level")
  print(Sys.time())
  print(gc())
  sub_dist_array=dist_array[second_index,,,drop=FALSE]
  sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*10,Fstat_method=F_method,zm=covariate_model_matrix)
  dist_pval[second_index]=sub_dist_pval
  thres=tol/(perm_num*10)
  second_index=which(dist_pval<thres)
  if(length(second_index)>0){
    print("2nd level")
    print(Sys.time())
    print(gc())
    sub_dist_array=dist_array[second_index,,,drop=FALSE]
    sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*100,Fstat_method=F_method,zm=covariate_model_matrix)
    dist_pval[second_index]=sub_dist_pval
    thres=tol/(perm_num*100)
    second_index=which(dist_pval<thres)
    if(length(second_index)>0){
      print("3rd level")
      print(Sys.time())
      print(gc())
      sub_dist_array=dist_array[second_index,,,drop=FALSE]
      sub_dist_pval=cal_permanova_pval2(sub_dist_array,phenotype,perm_num.min = perm_num*1000,Fstat_method=F_method,zm=covariate_model_matrix)
      dist_pval[second_index]=sub_dist_pval
    }
  }
}

## p-value calculation II(OPTIONAL)
second_index=which(is.na(dist_pval))
tol_missing_dist=0 # tolerate missing p-values number, if missing numer is no bigger than it, we will make it up with median of distance.
tol_missing_sample=dim(dist_array)[2]/2 #if effective sample less than this number, stop calculation

for(i2 in second_index){
  print(i2)
  x=dist_array[i2,,]
  #calculate zeros
  zero_sum=apply(is.na(x),2,sum)
  
  #first thres: to remove all zero inds
  flag=(zero_sum<nrow(x))
  if(sum(flag)>=tol_missing_sample){
    x=x[flag,flag]
    cur_pheno=phenotype[flag]
    
    #second thres:to remove inds with more than tolerate missing values
    zero_sum=apply(is.na(x),2,sum)
    flag=(zero_sum<=tol_missing_dist)
    if(sum(flag)>=tol_missing_sample){ 
      #third thres:to 
      x=x[flag,flag]
      cur_pheno=cur_pheno[flag]
      #add missing values:
      fill_index=which(!complete.cases(x))
      if(length(fill_index)>0){
        for(i_f in fill_index){
          for(j_f in fill_index){
            if(j_f>i_f){
              x[i_f,j_f]=median(c(x[,i_f],x[,j_f]),na.rm = TRUE) #here is a little recurrence, but that's OK...
              x[j_f,i_f]=x[i_f,j_f]
            }
          }
        }
      }
      dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = perm_num,zm=covariate_model_matrix), error = function(e) {NA} )
      thres=tol/perm_num
      if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
        dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*10),zm=covariate_model_matrix), error = function(e) {NA} )
        thres=tol/(perm_num*10)
        if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
          dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*100),zm=covariate_model_matrix), error = function(e) {NA} )
          thres=tol/(perm_num*100)
          if(!is.na(dist_pval[i2]) && dist_pval[i2]<thres){
            dist_pval[i2]=tryCatch(cal_permanova_pval(x,cur_pheno,Fstat_method=F_method,perm_num.min = (perm_num*1000),zm=covariate_model_matrix), error = function(e) {NA} )
          }
        }
      }
    }
  }
}

head(dist_pval)


```


##Individual level permutation example: DESeq2 analysis

```{r perm_DESeq2_analysis,eval=runcode}

dds=NA

if(perm_label>0){
  cur_info[,"diagnosis"]=cur_info[sample.int(nrow(cur_info),nrow(cur_info)),"diagnosis"]
}

dds=DESeqDataSetFromMatrix(countData = sim_matrix_bulk,
                           colData = cur_info,
                           design = ~ diagnosis)

dds=DESeq(dds)
deseq_pval=results(dds)$pvalue
deseq_pval[1:10]


```

##Individual level permutation example: MAST analysis

```{r perm_MAST_analysis,eval=runcode}

if(perm_label>0){
  #count cases and controls
  diag_info=paste0(colData(sca)$ind,":",colData(sca)$diagnosis)
  diag_kind=unique(diag_info)
  diag_kind=t(apply(as.matrix(diag_kind),1,function(x){return(unlist(strsplit(x,":")))}))
  
  #permute
  diag_kind[,2]=diag_kind[sample.int(nrow(diag_kind),nrow(diag_kind),replace=F),2]
  
  #match back to each individuals
  ind_index=match(colData(sca)$ind,diag_kind[,1])
  colData(sca)$diagnosis=as.factor(diag_kind[ind_index,2])
}

date()
b0 = zlm(formula = ~ diagnosis, sca = sca, parallel = TRUE)
date()
b1 = zlm(formula = ~ diagnosis + ( 1 | ind ), sca = sca, method = 'glmer', 
         ebayes = FALSE, parallel = TRUE)
date()

b0
b1

lrt0 = lrTest(b0, "diagnosis")
lrt1 = lrTest(b1, "diagnosis")

dim(lrt1)
lrt1[1,,]

MAST_pval0 = apply(lrt0, 1, function(x){x[3,3]})
length(MAST_pval0)
MAST_pval0[1:4]

MAST_pval1 = apply(lrt1, 1, function(x){x[3,3]})
length(MAST_pval1)
MAST_pval1[1:4]

```


##Individual level permutation example: Check and Save Results

```{r perm_save_results,eval=runcode, fig.dim = c(8,8)}
df2=NA

op=par(mfrow = c(2, 2), pty = "s", bty="n")

hist(dist_pval, main="Our Method", xlab="p-value")

hist(deseq_pval, main="DESeq2", xlab="p-value")

hist(MAST_pval0, main="MAST bayesglm", xlab="p-value")

hist(MAST_pval1, main="MAST glmer, mean-DE", xlab="p-value")

par(op)

df2 = data.frame(dist_pval, deseq_pval, MAST_pval0, MAST_pval1)
rownames(df2)=rownames(sub_mean)
colnames(df2)=c("dist_pval", "deseq_pval", "MAST_pval_bayesglm", "MAST_pval_glmer")
dim(df2)
df2[1:2,]

write.table(df2, paste0(data_dir,"perm_",perm_label,"_pvals_",cluster_tag,"_3k10.txt"), append=FALSE, 
            quote=FALSE, sep="\t", row.names = FALSE, col.names = TRUE)
```

# Session information
```{r ,eval=runcode}
sessionInfo()
```

# Reference




